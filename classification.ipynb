{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from transformers import AutoImageProcessor, ResNetForImageClassification,ResNetConfig\n",
    "import torch\n",
    "from abc import ABC,abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###DATASET PREP###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPaths(Path:str):\n",
    "    Path = Path\n",
    "    PathList = []\n",
    "    LabelList = []\n",
    "    DirList = os.listdir(Path)[:3]\n",
    "    for idx, x in enumerate(DirList):\n",
    "        for xx in os.listdir(f\"{Path}/{x}\"):\n",
    "            PathList.append(f\"{Path}/{x}/{xx}\")\n",
    "            LabelList.append(idx)\n",
    "    return PathList, LabelList\n",
    "\n",
    "trainPath = r\".\\ExperimentSet\"\n",
    "valPath = r\".\\ValidationSet\"\n",
    "originalPath = r\".\\Osteoporosis Knee X-ray\"\n",
    "\n",
    "trainPathList,trainLabelList = getAllPaths(trainPath)\n",
    "valPathList,valLabelList = getAllPaths(valPath)\n",
    "originalPathList,originalLabelList = getAllPaths(originalPath)\n",
    "\n",
    "trainDirList = os.listdir(trainPath)[:3]\n",
    "valDirList = os.listdir(valPath)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,x in enumerate(valDirList):\n",
    "    print(idx)\n",
    "    print(f\"{x}: {len(os.listdir(f'{valPath}/{x}'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPathList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "imageSizes = {}\n",
    "for x in valPathList:\n",
    "    img = Image.open(x).size\n",
    "    try:\n",
    "        imageSizes[str(img)] = imageSizes[str(img)] + 1\n",
    "    except KeyError:\n",
    "        imageSizes[str(img)] = 1\n",
    "imageSizes #varied image sizes, have to resize to 1024,1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as vF\n",
    "\n",
    "class OsteoTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, itemsPath:list, labels:list, transform=None, std = False, mean = False): #mean on if mean needs to be scaled, same goes for std\n",
    "        \n",
    "        self.itemsPath = itemsPath\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itemsPath)\n",
    "\n",
    "    def __getitem__(self,idx)->tuple[Image.Image,int]:\n",
    "        image = Image.open(self.itemsPath[idx]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "        \n",
    "        image.to(device = torch.device('cuda'))\n",
    "\n",
    "        return image, self.labels[idx], self.itemsPath[idx]          \n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Resize((224,224)),\n",
    "                                            # torchvision.transforms.CenterCrop((224,224)),\n",
    "                                            torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                                            ])                           \n",
    "valTransform = torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Resize((224,224)),\n",
    "                                            torchvision.transforms.RandomVerticalFlip(p=1),\n",
    "                                            torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                                            ])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "#inits dataset and dataloader + resamples training data to balance classes\n",
    "trainDataset = OsteoTorchDataset(trainPathList,trainLabelList,transform,std=False,mean=False)      \n",
    "valDataset = OsteoTorchDataset(valPathList,valLabelList,transform,std=False,mean=False)\n",
    "\n",
    "trainLabels = [y for x,y,z in trainDataset]\n",
    "unique_elements, counts = torch.unique(torch.tensor(trainLabels), return_counts=True)\n",
    "sampleWeights = 1. / counts.float() #I HAVE NO IDEA WHY THIS WORKS BUT IT DOES\n",
    "# MORAL OF THE STORY: FOLLOW THE FUCKING TUTORIAL DONT TRY CHANGING SHIT ON YOUR OWN ***EVEN IF THE DOCUMENTATION SAYS YOU SHOULD***\n",
    "trainSampler = WeightedRandomSampler(weights=[sampleWeights[x] for x in trainLabels],num_samples=len(trainDataset),replacement=True)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, batch_size = 8,shuffle=False,num_workers=0,sampler=trainSampler)\n",
    "valLoader = DataLoader(valDataset, batch_size = 16,shuffle=False,num_workers=0)\n",
    "\n",
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in trainLoader]), return_counts=True)#delete this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in valLoader]), return_counts=True)#delete this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(valLoader))\n",
    "temp[0][0].max()\n",
    "index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[0][0].min()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "index += 1\n",
    "# print(temp[1][index],temp[2][index])\n",
    "print((temp[0][index].numpy()*255).max().astype(np.uint8))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "print(str(temp[2][index]))\n",
    "# Plot the first image\n",
    "axs[0].imshow(((temp[0][index]+1)/2).permute(1, 2, 0))\n",
    "axs[0].set_title('Image 1')\n",
    "\n",
    "# Plot the second image\n",
    "axs[1].imshow(Image.open(temp[2][index]).convert('RGB'))\n",
    "axs[1].set_title('Image 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models here\n",
    "import sklearn.metrics\n",
    "from resnetModel import ResNet50\n",
    "import sklearn\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torcheval.metrics.functional import multiclass_f1_score,multiclass_confusion_matrix,multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from torch import mode\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from abc import ABC\n",
    "\n",
    "#FIXME identify bottleneck\n",
    "#FIXME clean up my fucking code ffs its so UGLY\n",
    "\n",
    "class ExperimentModel(L.LightningModule,ABC):\n",
    "\n",
    "    existingModels = []\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        ExperimentModel.existingModels.append(self)\n",
    "        super().__init__()\n",
    "\n",
    "        #init the models here in a subclass\n",
    "\n",
    "        self.num_class = 3\n",
    "        self.classWeight = torch.tensor([0.204, 0.052, 0.175],device='cuda')\n",
    "\n",
    "        self.dump = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward():\n",
    "        pass\n",
    "    \n",
    "    def training_step(self,batch):\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "        self.dump.append([path,label])\n",
    "        loss = F.cross_entropy(output,label,weight=self.classWeight)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", multiclass_accuracy(output.argmax(1),label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "\n",
    "        preds = output.argmax(1)\n",
    "        loss = F.cross_entropy(output,label)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_F1\", sklearn.metrics.f1_score(label.cpu(),preds.cpu(),labels = range(self.num_class),average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", multiclass_accuracy(preds,label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    \n",
    "    # def on_validation_epoch_end(self) -> None:\n",
    "\n",
    "    #     accuracy = torch.stack(self.valScore).mean()\n",
    "    #     self.bestValScore.append(accuracy)\n",
    "    #     self.bestValPreds.append(torch.cat(self.valPreds))\n",
    "    #     self.bestValLabels.append(torch.cat(self.valLabels))\n",
    "        # self.log(\"val_acc_F1\", multiclass_f1_score(torch.cat(self.valPreds),torch.cat(self.valLabels),num_classes=self.num_class,average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "       \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        data,label = batch\n",
    "        return self(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import resnetModel\n",
    "\n",
    "class GradCamTrack(ExperimentModel): #Class for GradCam visualization, should be subclassed by the model to be visualized with a new init and a forward + hook\n",
    "    \n",
    "    def __init__(self,) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gradients = None\n",
    "        self.cachedActivation = None\n",
    "\n",
    "    # cachedActivation is no longer needed, but kept for legacy purposes\n",
    "    def activations_hook(self, grad, imageActivation = None):\n",
    "        if imageActivation != None:\n",
    "            self.cachedActivation = imageActivation\n",
    "        self.gradients = grad\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)\n",
    "     \n",
    "    # Runs CAM and overlays the image\n",
    "    # this is the function to call for visualization\n",
    "    def visualize(self,dataloader:torch.utils.data.dataloader.DataLoader): #TODO FIX THIS for generalization\n",
    "        out,path,label = self.CAM(dataloader)\n",
    "        for i in range(len(out)):\n",
    "            self.visualizeAndWrite(out[i],path[i],label[i])\n",
    "        return out,path\n",
    "    \n",
    "    # Visualizes the Gradients of the last conv layer of model\n",
    "    # can take in torch dataloader or list of [img],[label],[path]\n",
    "    def CAM(self,dataloader:torch.utils.data.dataloader.DataLoader):\n",
    "        self.eval()\n",
    "        if isinstance(dataloader,torch.utils.data.dataloader.DataLoader):\n",
    "            img,label,path = next(iter(dataloader))\n",
    "\n",
    "        else:\n",
    "            img,label,path = dataloader\n",
    "\n",
    "        img = img.to(device = torch.device('cuda'))\n",
    "        heatmapList = []\n",
    "        for i in range(len(img)):\n",
    "            pred = self(torch.unsqueeze(img[i],0))\n",
    "            # get the gradient of the output with respect to the parameters of the model\n",
    "            pred[:, label[i].item()].backward()\n",
    "\n",
    "            # pull the gradients out of the model\n",
    "            gradients = self.get_activations_gradient()\n",
    "\n",
    "            # pool the gradients across the channels\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "            # get the activations of the last convolutional layer\n",
    "            if self.cachedActivation != None:\n",
    "                activations = self.cachedActivation.detach()\n",
    "                print(activations - self.get_activations(torch.unsqueeze(img[i],0)).detach())\n",
    "                print(f\"cached:{activations.shape}\")\n",
    "            else:\n",
    "                activations = self.get_activations(torch.unsqueeze(img[i],0)).detach() # DONT forget to apply image changes here too\n",
    "                print(f\"not cached:{activations.shape}\")\n",
    "            # weight the channels by corresponding gradients\n",
    "            print(f\"pooled shape: {pooled_gradients.shape}\")\n",
    "            for j in range(pooled_gradients.shape[0]):\n",
    "                activations[:, j, :, :] *= pooled_gradients[j]\n",
    "                \n",
    "            # average the channels of the activations\n",
    "            heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "            print(heatmap.shape)\n",
    "\n",
    "            # relu on top of the heatmap\n",
    "            # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "            heatmap = np.maximum(heatmap.detach().cpu(), 0)\n",
    "\n",
    "            # normalize the heatmap\n",
    "            heatmap /= torch.max(heatmap)\n",
    "\n",
    "            # draw the heatmap\n",
    "            heatmapList.append(heatmap)\n",
    "            print(heatmap.shape)\n",
    "\n",
    "        return heatmapList,path,label\n",
    "    \n",
    "\n",
    "    #writes files to disk for visualization, format: model_epoch_label_pred/image.jpg\n",
    "    def visualizeAndWrite(self,out:torch.tensor,path:str,label:str,epoch=False): #TODO Implement this with tensorboard\n",
    "        if not epoch:\n",
    "            epoch = self.current_epoch\n",
    "\n",
    "        labelDict = {0:'N',1:'OP',2:'OS'}\n",
    "            \n",
    "        img = cv2.imread(path)\n",
    "        heatmap = cv2.resize(out.numpy(), (img.shape[1], img.shape[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = heatmap * 0.4 + img\n",
    "        match = re.findall(r\"[A-Z,a-z]*\",path)[-1]\n",
    "        path = re.sub(r\"[A-Z,a-z]*\",labelDict[match],path)\n",
    "        cv2.imwrite(rf'./visualizations/gradCam/{self.__class__.__name__}_{epoch}__{str(label)}_{path.split(r\"/\")[-1]}', superimposed_img)\n",
    "\n",
    "\n",
    "class VGGModel(GradCamTrack):\n",
    "    def __init__(self,vgg:torchvision.models.vgg.VGG) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = vgg.features[:36]\n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = vgg.classifier\n",
    "        self.classifier[6] = torch.nn.Linear(4096,self.num_class)\n",
    "\n",
    "\n",
    "    def forward(self,inTensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        # # register the hook\n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.flatten(1,-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class ResnetModel(GradCamTrack):\n",
    "    def __init__(self,resnet:torchvision.models.resnet.ResNet) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = torch.nn.Sequential(*[x for x in resnet.children()][:-2])\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = torch.nn.Linear(2048, self.num_class)\n",
    "        # self.model.layer4[2] = resnetModel.CustBottleneck(2048,512,self.activations_hook)\n",
    "        # self.model.fc = torch.nn.Linear(2048,3)\n",
    "        \n",
    "    def forward(self,inTensor:torch.tensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', pretrained=True)\n",
    "resnet50 = ResnetModel(model)\n",
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGGModel(torchvision.models.vgg19(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "for x in ExperimentModel.existingModels:\n",
    "    print(x.__class__.__name__)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Metric to monitor\n",
    "        patience=5000,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=False,        # Verbosity mode\n",
    "        mode='min'           # Mode can be 'min', 'max', or 'auto'\n",
    "    )\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=f\"{x.__class__.__name__}\")\n",
    "    \n",
    "\n",
    "    trainer = L.Trainer(max_epochs = 10,accelerator='gpu', devices='auto', precision='16-mixed',logger=logger)\n",
    "    trainer.fit(model=x,train_dataloaders=trainLoader,val_dataloaders=valLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', pretrained=True)\n",
    "resnetPath = r'C:\\Users\\assaw\\Documents\\c_stuff\\Python\\machine learning\\ISAIConference\\tb_logs\\ResnetModel\\version_20\\checkpoints'\n",
    "resnet50 = ResnetModel.load_from_checkpoint('\\\\'.join([resnetPath,os.listdir(resnetPath)[-1]]),resnet = model)\n",
    "torch.cuda.empty_cache()\n",
    "out,label = resnet50.visualize(valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VGGModel.load_from_checkpoint(r'tb_logs\\VGGModel\\version_26\\checkpoints\\epoch=19-step=720.ckpt',vgg = torchvision.models.vgg19(pretrained=False))\n",
    "outvgg,path = model.visualize(valLoader)\n",
    "\n",
    "plt.imshow(outvgg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,_,_ = next(iter(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze(img[0],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.eval()\n",
    "img,lab,path = next(iter(trainLoader))\n",
    "pred = resnet50(torch.unsqueeze(img[0],0))\n",
    "print(pred)\n",
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 1].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = resnet50.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = resnet50.get_activations(torch.unsqueeze(img[0],0)).detach()\n",
    "print(activations.shape)\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(out[1][0])\n",
    "heatmap = cv2.resize(out[0][0].numpy(), (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./test.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.cuda.empty_cache()\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.204, 0.052, 0.175],device='cuda'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "accHistory = []\n",
    "lossHistory = []\n",
    "valAccHistory = []\n",
    "valLabs = []\n",
    "valPreds = []\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = []\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for inputs, labels, _ in trainLoader:\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "        running_accuracy.append(accuracy)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1} - Loss: {running_loss / len(trainLoader)}\")\n",
    "    print(F\"Accuracy: {sum(running_accuracy)/len(running_accuracy)}\")\n",
    "    accHistory.append(sum(running_accuracy)/len(running_accuracy))\n",
    "    lossHistory.append(running_loss / len(trainLoader))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        runningValAccHistory = []\n",
    "        runningValLabs = []\n",
    "        runningValPreds = []\n",
    "        for inputs, labels, _ in valLoader:\n",
    "\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the predicted labels\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "\n",
    "            runningValAccHistory.append(accuracy)\n",
    "            runningValLabs.append(labels)\n",
    "            runningValPreds.append(predicted_labels)\n",
    "\n",
    "        # print(f\"Validation Loss: {loss.item()}\")\n",
    "        valPreds.append(runningValPreds)\n",
    "        valLabs.append(runningValLabs)\n",
    "        print(f\"Validation Accuracy: {sum(runningValAccHistory)/len(valLoader)}\")\n",
    "        valAccHistory.append(sum(runningValAccHistory)/len(valLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "idx = 25\n",
    "predsTest = torch.cat(valPreds[idx-1])\n",
    "labelsTest = torch.cat(valLabs[idx-1])\n",
    "print(valAccHistory[idx-1])\n",
    "print(classification_report(predsTest.cpu(),labelsTest.cpu()))\n",
    "cm= confusion_matrix(predsTest.cpu(),labelsTest.cpu(),normalize='true')\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f',)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input , label, _ = next(iter(valLoader))\n",
    "# Move the inputs and labels to the device\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "predicted_labels = torch.argmax(outputs, dim=1)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with the data\n",
    "df = pd.DataFrame({'Epoch': range(len(accHistory)), 'Accuracy': accHistory, 'Loss': lossHistory, 'Validation Accuracy': valAccHistory})\n",
    "\n",
    "# Create the line plot\n",
    "sns.relplot(data=df, x='Epoch', y='Accuracy', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Loss', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Validation Accuracy', kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
