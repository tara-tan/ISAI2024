{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import torch\n",
    "from abc import ABC,abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "def getAllPaths(path:str, excludeList = None):\n",
    "    path = path\n",
    "    pathList = []\n",
    "    labelList = []\n",
    "    dirList = os.listdir(path)[:3]\n",
    "    for idx, x in enumerate(dirList):\n",
    "        for xx in os.listdir(f\"{path}/{x}\"):\n",
    "            pathList.append(f\"{path}/{x}/{xx}\")\n",
    "            labelList.append(idx)\n",
    "    if excludeList:\n",
    "        pathList = [x for x in pathList if not any(xx in x for xx in excludeList)]\n",
    "    return pathList, labelList\n",
    "\n",
    "trainPath = r\".\\ExperimentSet\"\n",
    "valPath = r\".\\ValidationSet\"\n",
    "originalPath = r\".\\Osteoporosis Knee X-ray\"\n",
    "\n",
    "excludeList = ['Rp','Rn','Sup','Sdown','Sleft','Sright']\n",
    "\n",
    "trainPathList,trainLabelList = getAllPaths(trainPath)\n",
    "# trainPathList,trainLabelList = getAllPaths(trainPath,excludeList)\n",
    "valPathList,valLabelList = getAllPaths(valPath)\n",
    "originalPathList,originalLabelList = getAllPaths(originalPath)\n",
    "\n",
    "trainDirList = os.listdir(trainPath)[:3]\n",
    "valDirList = os.listdir(valPath)[:3]\n",
    "print(trainPathList[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check val distribution (this should be 10,10,10)\n",
    "#this does not account for excluded names\n",
    "trainDist = []\n",
    "for idx,x in enumerate(valDirList):\n",
    "    print(f\"val {x}: {len(os.listdir(f'{valPath}/{x}'))}\")\n",
    "\n",
    "for idx,x in enumerate(trainDirList):\n",
    "    print(f\"train {x}: {len(os.listdir(f'{trainPath}/{x}'))}\")\n",
    "    \n",
    "    trainDist.append(len(os.listdir(f'{trainPath}/{x}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check image sizes\n",
    "from PIL import Image\n",
    "imageSizes = {}\n",
    "for x in trainPathList:\n",
    "    img = Image.open(x).size\n",
    "    try:\n",
    "        imageSizes[str(img)] = imageSizes[str(img)] + 1\n",
    "    except KeyError:\n",
    "        imageSizes[str(img)] = 1\n",
    "imageSizes #varied image sizes, have to resize to 1024,1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as vF\n",
    "\n",
    "class OsteoTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, itemsPath:list, labels:list, transform=None): \n",
    "        \n",
    "        self.itemsPath = itemsPath\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itemsPath)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image = Image.open(self.itemsPath[idx]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "        \n",
    "        image.to(device = torch.device('cuda'))\n",
    "\n",
    "        return image, self.labels[idx], self.itemsPath[idx]          \n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.RandomResizedCrop((224,224),scale=(0.666,1.0)),\n",
    "                                            # torchvision.transforms.Resize((224,224)),\n",
    "                                            # torchvision.transforms.CenterCrop((224,224)),\n",
    "                                            # torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                                            ])                           \n",
    "valTransform = torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            # torchvision.transforms.Resize((224,224)),\n",
    "                                            # torchvision.transforms.RandomHorizontalFlip(p=1),\n",
    "                                            torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                                            ])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to save Processed images to disk to save on processing time\n",
    "# import PIL\n",
    "# trainDataset = OsteoTorchDataset(trainPathList,trainLabelList,transform)\n",
    "# for x in trainDataset:\n",
    "#     arr = ((x[0].permute(1,2,0)*255).numpy().astype(np.uint8))\n",
    "#     img = PIL.Image.fromarray(arr,mode=\"RGB\")\n",
    "#     img.save(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "#inits dataset and dataloader + resamples training data to balance classes\n",
    "trainDataset = OsteoTorchDataset(trainPathList,trainLabelList,transform)      \n",
    "valDataset = OsteoTorchDataset(valPathList,valLabelList,valTransform)\n",
    "\n",
    "unique_elements, counts = torch.unique(torch.tensor(trainLabelList), return_counts=True)\n",
    "sampleWeights = 1. / counts.float() #I HAVE NO IDEA WHY THIS WORKS BUT IT DOES\n",
    "# MORAL OF THE STORY: FOLLOW THE FUCKING TUTORIAL DONT TRY CHANGING SHIT ON YOUR OWN ***EVEN IF THE DOCUMENTATION SAYS YOU SHOULD***\n",
    "# trainSampler = WeightedRandomSampler(weights=[sampleWeights[x] for x in trainLabelList],num_samples=len(trainDataset),replacement=True)\n",
    "\n",
    "trainSampler = WeightedRandomSampler(weights=[sampleWeights[x] for x in trainLabelList],num_samples=min(trainDist)*3,replacement=True)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, batch_size = 8,shuffle=False,num_workers=0,sampler=trainSampler)\n",
    "valLoader = DataLoader(valDataset, batch_size = 8,shuffle=False,num_workers=0)\n",
    "\n",
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in trainLoader]), return_counts=True)#delete this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in valLoader]), return_counts=True)#delete this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(trainLoader))\n",
    "index = -1\n",
    "\n",
    "temp[0][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[0][0].min()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "index += 1\n",
    "# print(temp[1][index],temp[2][index])\n",
    "print((temp[0][index].numpy()*255).max().astype(np.uint8))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "print(str(temp[2][index]))\n",
    "# Plot the first image\n",
    "axs[0].imshow(((temp[0][index]+1)/2).permute(1, 2, 0))\n",
    "axs[0].set_title('Image 1')\n",
    "\n",
    "# Plot the second image\n",
    "axs[1].imshow(Image.open(temp[2][index]).convert('RGB'))\n",
    "axs[1].set_title('Image 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL PREP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models here\n",
    "import sklearn.metrics\n",
    "from resnetModel import ResNet50\n",
    "import sklearn\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torcheval.metrics.functional import multiclass_f1_score,multiclass_confusion_matrix,multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from torch import mode\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from abc import ABC\n",
    "\n",
    "#FIXME clean up my fucking code ffs its so UGLY\n",
    "\n",
    "class ExperimentModel(L.LightningModule,ABC):\n",
    "\n",
    "    existingModels = []\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        ExperimentModel.existingModels.append(self)\n",
    "        super().__init__()\n",
    "\n",
    "        #init the models here in a subclass\n",
    "        self.imbalanceWeight = 0\n",
    "        self.num_class = 3\n",
    "        self.classWeight = torch.tensor([0.204, 0.052, 0.175],device='cuda')*self.imbalanceWeight\n",
    "        \n",
    "        if (torch.tensor([0.204, 0.052, 0.175],device='cuda')*0).detach()[0].item() == 0:\n",
    "            self.classWeight = torch.ones(self.classWeight.size(),device='cuda')\n",
    "\n",
    "        self.dump = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward():\n",
    "        pass\n",
    "    \n",
    "    def training_step(self,batch):\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "        self.dump.append([path,label])\n",
    "        loss = F.cross_entropy(output,label,weight=self.classWeight)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", multiclass_accuracy(output.argmax(1),label,num_classes=self.num_class), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "\n",
    "        preds = output.argmax(1)\n",
    "        loss = F.cross_entropy(output,label)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_F1\", sklearn.metrics.f1_score(label.cpu(),preds.cpu(),labels = range(self.num_class),average = 'macro',zero_division=1), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", multiclass_accuracy(preds,label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    \n",
    "    # def on_validation_epoch_end(self) -> None:\n",
    "\n",
    "    #     accuracy = torch.stack(self.valScore).mean()\n",
    "    #     self.bestValScore.append(accuracy)\n",
    "    #     self.bestValPreds.append(torch.cat(self.valPreds))\n",
    "    #     self.bestValLabels.append(torch.cat(self.valLabels))\n",
    "        # self.log(\"val_acc_F1\", multiclass_f1_score(torch.cat(self.valPreds),torch.cat(self.valLabels),num_classes=self.num_class,average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "       \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        data,label = batch\n",
    "        return self(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import resnetModel\n",
    "import shutil\n",
    "\n",
    "class GradCamTrack(ExperimentModel): #Class for GradCam visualization, should be subclassed by the model to be visualized with a new init and a forward + hook\n",
    "    \n",
    "    def __init__(self,) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gradients = None\n",
    "        self.cachedActivation = None\n",
    "\n",
    "    # cachedActivation is no longer needed, but kept for legacy purposes\n",
    "    def activations_hook(self, grad, imageActivation = None):\n",
    "        if imageActivation != None:\n",
    "            self.cachedActivation = imageActivation\n",
    "        self.gradients = grad\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)\n",
    "     \n",
    "    # Runs CAM and overlays the image\n",
    "    # this is the function to call for visualization\n",
    "    def visualize(self,dataloader:torch.utils.data.dataloader.DataLoader): #TODO FIX THIS for generalization\n",
    "        with torch.inference_mode(False):\n",
    "            out,path,pred = self.CAM(dataloader)\n",
    "        try:\n",
    "            os.mkdir(rf'./visualizations/gradCam/{self.__class__.__name__}/')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(rf'./visualizations/gradCam/{self.__class__.__name__}/{self.current_epoch}')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "        os.mkdir(rf'./visualizations/gradCam/{self.__class__.__name__}/{self.current_epoch}')\n",
    "        for i in range(len(out)):\n",
    "            \n",
    "            self.visualizeAndWrite(out[i],path[i],pred[i])\n",
    "        return pred,path\n",
    "    \n",
    "    # Visualizes the Gradients of the last conv layer of model\n",
    "    # can take in torch dataloader or ([img],[label],[path])\n",
    "    def CAM(self,dataloader:torch.utils.data.dataloader.DataLoader):\n",
    "        \n",
    "        self.eval()\n",
    "        self.requires_grad_()\n",
    "        predList = []\n",
    "\n",
    "        pathList = []\n",
    "        \n",
    "        heatmapList = []\n",
    "\n",
    "        for x in dataloader:\n",
    "            img,label,path = x\n",
    "\n",
    "            img = img.to(device = torch.device('cuda'))\n",
    "            for i in range(len(img)):\n",
    "                out = self(torch.unsqueeze(img[i],0).requires_grad_())\n",
    "                pred= out.argmax(1).item()\n",
    "                predList.append(pred)\n",
    "                # get the gradient of the output with respect to the parameters of the model\n",
    "                out[:, pred].backward()\n",
    "\n",
    "                # pull the gradients out of the model\n",
    "                gradients = self.get_activations_gradient()\n",
    "\n",
    "                # pool the gradients across the channels\n",
    "                pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "                # get the activations of the last convolutional layer\n",
    "                if self.cachedActivation != None:\n",
    "                    activations = self.cachedActivation.detach()\n",
    "                else:\n",
    "                    activations = self.get_activations(torch.unsqueeze(img[i],0)).detach() # DONT forget to apply image changes here too\n",
    "                # weight the channels by corresponding gradients\n",
    "                for j in range(pooled_gradients.shape[0]):\n",
    "                    activations[:, j, :, :] *= pooled_gradients[j]\n",
    "                    \n",
    "                # average the channels of the activations\n",
    "                heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "                # relu on top of the heatmap\n",
    "                # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "                heatmap = np.maximum(heatmap.detach().cpu(), 0)\n",
    "\n",
    "                # normalize the heatmap\n",
    "                heatmap /= torch.max(heatmap)\n",
    "\n",
    "                # draw the heatmap\n",
    "                heatmapList.append(heatmap)\n",
    "                \n",
    "                pathList.append(path[i])\n",
    "\n",
    "                self.zero_grad()\n",
    "\n",
    "        return heatmapList,pathList,predList\n",
    "    \n",
    "\n",
    "    #writes files to disk for visualization, format: model_epoch_label_pred/image.jpg\n",
    "    def visualizeAndWrite(self,out:torch.tensor,path:str,pred:str,epoch=False): #TODO Implement this with logger\n",
    "        if not epoch:\n",
    "            epoch = self.current_epoch\n",
    "\n",
    "        labelDict = {0:'N',1:'OP',2:'OS'}\n",
    "            \n",
    "        img = cv2.imread(path)\n",
    "        heatmap = cv2.resize(out.numpy(), (img.shape[1], img.shape[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = heatmap * 0.4 + img\n",
    "        cv2.imwrite(rf'./visualizations/gradCam/{self.__class__.__name__}/{epoch}/pred{str(labelDict[pred])}_{path.split(r\"/\")[-1]}', superimposed_img)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        super().on_validation_epoch_end()\n",
    "        pred,path = self.visualize(valLoader)\n",
    "        label = [x.split(r\"/\")[-2] for x in path]\n",
    "        labelDict = {'normal':0,'osteopenia':1,'osteoporosis':2}\n",
    "        \n",
    "        label = [labelDict[x] for x in label]\n",
    "        # self.log(\"classification report\",classification_report(label,pred))\n",
    "        print(classification_report(label,pred,zero_division=1))\n",
    "        plt.clf()\n",
    "        cm= confusion_matrix(label,pred,labels=[0,1,2],normalize='true',zero_division=1)\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f',)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        # self.log({'Confusion Matrix': plt.gcf()}) #watch out for BUG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VGGModel(GradCamTrack):\n",
    "    def __init__(self,vgg:torchvision.models.vgg.VGG) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = vgg.features[:36]\n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = vgg.classifier\n",
    "        self.classifier[6] = torch.nn.Linear(4096,self.num_class)\n",
    "\n",
    "\n",
    "    def forward(self,inTensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        # # register the hook\n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.max_pool(x)\n",
    "        x = x.flatten(1,-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class ResnetModel(GradCamTrack):\n",
    "    def __init__(self,resnet:torchvision.models.resnet.ResNet) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = torch.nn.Sequential(*[x for x in resnet.children()][:-2])\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = torch.nn.Linear(2048, self.num_class)\n",
    "        # self.model.layer4[2] = resnetModel.CustBottleneck(2048,512,self.activations_hook)\n",
    "        # self.model.fc = torch.nn.Linear(2048,3)\n",
    "        \n",
    "    def forward(self,inTensor:torch.tensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class InceptionModel(GradCamTrack):\n",
    "    def __init__(self,inception:torchvision.models.inception) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = torch.nn.Sequential(*[x for x in inception.children()][:-3])\n",
    "        self.classifier = torch.nn.Sequential(*[x for x in inception.children()][-3:])\n",
    "        self.classifier[-1] = torch.nn.Linear(in_features=2048, out_features=self.num_class, bias=True)\n",
    "        \n",
    "    def forward(self,inTensor:torch.tensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class EfficientNetModel(GradCamTrack):\n",
    "    def __init__(self,effNet:torchvision.models.efficientnet) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = effNet.features\n",
    "        self.avgpool = effNet.avgpool\n",
    "        self.classifier = effNet.classifier\n",
    "        self.classifier[1] = torch.nn.Linear(1280,self.num_class)\n",
    "        \n",
    "        \n",
    "    def forward(self,inTensor:torch.tensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init models here\n",
    "\n",
    "ExperimentModel.existingModels = []\n",
    "# resnet50 = ResnetModel(torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', pretrained=True))\n",
    "\n",
    "vgg19 = VGGModel(torchvision.models.vgg19(pretrained=True))\n",
    "\n",
    "# inceptionv3 = InceptionModel(torch.hub.load('pytorch/vision:v0.19.0', 'inception_v3', pretrained=True))\n",
    "# efficientNetv2 = EfficientNetModel(torch.hub.load('pytorch/vision:v0.19.0', 'efficientnet_v2_l', pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | features_conv | Sequential | 20.0 M | train\n",
      "1 | max_pool      | MaxPool2d  | 0      | train\n",
      "2 | classifier    | Sequential | 119 M  | train\n",
      "-----------------------------------------------------\n",
      "139 M     Trainable params\n",
      "0         Non-trainable params\n",
      "139 M     Total params\n",
      "558.330   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f73605fe6043d3b63eaef4fbb3fdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      0.70      0.42        10\n",
      "           2       0.14      0.10      0.12        10\n",
      "\n",
      "    accuracy                           0.27        30\n",
      "   macro avg       0.15      0.27      0.18        30\n",
      "weighted avg       0.15      0.27      0.18        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d61cc989f634cd59a040a7a3fbe243e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9dd89a52d04c6591cf09d3e749a77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.39      0.70      0.50        10\n",
      "           2       0.33      0.40      0.36        10\n",
      "\n",
      "    accuracy                           0.37        30\n",
      "   macro avg       0.24      0.37      0.29        30\n",
      "weighted avg       0.24      0.37      0.29        30\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd31fa40ce04064982fe506a3ec67f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      0.70      0.42        10\n",
      "           2       0.29      0.20      0.24        10\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.20      0.30      0.22        30\n",
      "weighted avg       0.20      0.30      0.22        30\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c128f4b133ae40648cdd4620de7f9142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.33      0.70      0.45        10\n",
      "           2       0.22      0.20      0.21        10\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.19      0.30      0.22        30\n",
      "weighted avg       0.19      0.30      0.22        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training loop\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger,TensorBoardLogger\n",
    "from lightning.pytorch.profilers import AdvancedProfiler\n",
    "\n",
    "for x in ExperimentModel.existingModels:\n",
    "    logDirectory = f\"./lightning_logs/{x.__class__.__name__}\"\n",
    "    versionList = os.listdir(logDirectory)\n",
    "    versionList.sort(key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "    print(x.__class__.__name__)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_acc_F1',  # Metric to monitor\n",
    "        patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=False,        # Verbosity mode\n",
    "        mode='min'           # Mode can be 'min', 'max', or 'auto'\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=\"my/path/\", save_top_k=2, monitor=\"val_acc_F1\")\n",
    "\n",
    "    profiler = AdvancedProfiler(dirpath=\"./lightning_logs\", filename=\"profiler_logs\")\n",
    "    \n",
    "    tbLogger = TensorBoardLogger(\"lightning_logs\",name=f\"{x.__class__.__name__}\")\n",
    "    wandb_logger = WandbLogger(project=f\"{x.__class__.__name__}\",name=f\"{x.__class__.__name__}\")\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "                        profiler = profiler,\n",
    "                        max_epochs = 50,\n",
    "                        min_epochs = 25,\n",
    "                        accelerator ='gpu', \n",
    "                        devices = 'auto', \n",
    "                        precision = '16-mixed',\n",
    "                        logger = tbLogger,\n",
    "                        callbacks = [early_stopping,checkpoint_callback],\n",
    "                    )\n",
    "    \n",
    "    trainer.fit(model=x,train_dataloaders=trainLoader,val_dataloaders=valLoader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCam Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', pretrained=True)\n",
    "resnetPath = r'C:\\Users\\assaw\\Documents\\c_stuff\\Python\\machine learning\\ISAIConference\\tb_logs\\ResnetModel\\version_22\\checkpoints'\n",
    "resnet50 = ResnetModel.load_from_checkpoint('\\\\'.join([resnetPath,os.listdir(resnetPath)[-1]]),resnet = model)\n",
    "torch.cuda.empty_cache()\n",
    "resnet50.to(device = torch.device('cuda'))\n",
    "# out,label = resnet50.visualize(valLoader)\n",
    "resnet50.on_validation_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VGGModel.load_from_checkpoint(r'tb_logs\\VGGModel\\version_26\\checkpoints\\epoch=19-step=720.ckpt',vgg = torchvision.models.vgg19(pretrained=False))\n",
    "outvgg,path = model.visualize(valLoader)\n",
    "\n",
    "plt.imshow(outvgg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic pytorch for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.cuda.empty_cache()\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.204, 0.052, 0.175],device='cuda'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "accHistory = []\n",
    "lossHistory = []\n",
    "valAccHistory = []\n",
    "valLabs = []\n",
    "valPreds = []\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = []\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for inputs, labels, _ in trainLoader:\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "        running_accuracy.append(accuracy)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1} - Loss: {running_loss / len(trainLoader)}\")\n",
    "    print(F\"Accuracy: {sum(running_accuracy)/len(running_accuracy)}\")\n",
    "    accHistory.append(sum(running_accuracy)/len(running_accuracy))\n",
    "    lossHistory.append(running_loss / len(trainLoader))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        runningValAccHistory = []\n",
    "        runningValLabs = []\n",
    "        runningValPreds = []\n",
    "        for inputs, labels, _ in valLoader:\n",
    "\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the predicted labels\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "\n",
    "            runningValAccHistory.append(accuracy)\n",
    "            runningValLabs.append(labels)\n",
    "            runningValPreds.append(predicted_labels)\n",
    "\n",
    "        # print(f\"Validation Loss: {loss.item()}\")\n",
    "        valPreds.append(runningValPreds)\n",
    "        valLabs.append(runningValLabs)\n",
    "        print(f\"Validation Accuracy: {sum(runningValAccHistory)/len(valLoader)}\")\n",
    "        valAccHistory.append(sum(runningValAccHistory)/len(valLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "idx = 25\n",
    "predsTest = torch.cat(valPreds[idx-1])\n",
    "labelsTest = torch.cat(valLabs[idx-1])\n",
    "print(valAccHistory[idx-1])\n",
    "print(classification_report(predsTest.cpu(),labelsTest.cpu()))\n",
    "cm= confusion_matrix(predsTest.cpu(),labelsTest.cpu(),normalize='true')\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f',)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with the data\n",
    "df = pd.DataFrame({'Epoch': range(len(accHistory)), 'Accuracy': accHistory, 'Loss': lossHistory, 'Validation Accuracy': valAccHistory})\n",
    "\n",
    "# Create the line plot\n",
    "sns.relplot(data=df, x='Epoch', y='Accuracy', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Loss', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Validation Accuracy', kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
