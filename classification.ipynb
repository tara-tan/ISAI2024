{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from transformers import AutoImageProcessor, ResNetForImageClassification,ResNetConfig\n",
    "import torch\n",
    "from abc import ABC,abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###DATASET PREP###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath = r\"C:\\Users\\assaw\\Documents\\c_stuff\\Python\\machine learning\\ISAIConference\\testIm\"\n",
    "pathList = []\n",
    "labelList = []\n",
    "dirList = os.listdir(projectPath)[:3]\n",
    "for idx, x in enumerate(dirList):\n",
    "    for xx in os.listdir(f\"{projectPath}/{x}\"):\n",
    "        pathList.append(f\"{projectPath}/{x}/{xx}\")\n",
    "        labelList.append(idx)\n",
    "        \n",
    "# dir structure: projectPath/label/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "normal: 57\n",
      "1\n",
      "osteopenia: 240\n",
      "2\n",
      "osteoporosis: 73\n"
     ]
    }
   ],
   "source": [
    "for idx,x in enumerate(dirList):\n",
    "    print(idx)\n",
    "    print(f\"{x}: {len(os.listdir(f'{projectPath}/{x}'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(244, 244)': 370}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "imageSizes = {}\n",
    "for x in pathList:\n",
    "    img = Image.open(x).size\n",
    "    try:\n",
    "        imageSizes[str(img)] = imageSizes[str(img)] + 1\n",
    "    except KeyError:\n",
    "        imageSizes[str(img)] = 1\n",
    "imageSizes #varied image sizes, have to resize to 1024,1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as vF\n",
    "\n",
    "class OsteoTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, itemsPath:list, labels:list, transform=None, std = False, mean = False): #mean on if mean needs to be scaled, same goes for std\n",
    "        \n",
    "        self.itemsPath = itemsPath\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itemsPath)\n",
    "\n",
    "    def __getitem__(self,idx)->tuple[Image.Image,int]:\n",
    "        image = Image.open(self.itemsPath[idx]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "        \n",
    "        image.to(device = torch.device('cuda'))\n",
    "\n",
    "        return image, self.labels[idx], self.itemsPath[idx]          \n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            # torchvision.transforms.Resize((256,256)),\n",
    "                                            # torchvision.transforms.CenterCrop((224,224)),\n",
    "                                            torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                                            ])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 101,  97])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "osteoDataset = OsteoTorchDataset(pathList,labelList,transform,std=False,mean=False)      \n",
    "train,val = torch.utils.data.random_split(osteoDataset,[0.8,0.2])#MAY BUG\n",
    "trainLabels = [y for x,y,z in train]\n",
    "unique_elements, counts = torch.unique(torch.tensor(trainLabels), return_counts=True)\n",
    "sampleWeights = 1. / counts.float() #I HAVE NO IDEA WHY THIS WORKS BUT IT DOES\n",
    "# MORAL OF THE STORY: FOLLOW THE FUCKING TUTORIAL DONT TRY CHANGING SHIT ON YOUR OWN ***EVEN IF THE DOCUMENTATION SAYS YOU SHOULD***\n",
    "trainSampler = WeightedRandomSampler(weights=[sampleWeights[x] for x in trainLabels],num_samples=len(train),replacement=True)\n",
    "\n",
    "trainLoader = DataLoader(train, batch_size = 8,shuffle=False,num_workers=0,sampler=trainSampler)\n",
    "valLoader = DataLoader(val, batch_size = 8,shuffle=False,num_workers=0)\n",
    "\n",
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in trainLoader]), return_counts=True)#delet this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 48, 14])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in valLoader]), return_counts=True)#delet this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = next(iter(trainLoader))\n",
    "temp[0][0].max()\n",
    "index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "C:\\Users\\assaw\\Documents\\c_stuff\\Python\\machine learning\\ISAIConference\\testIm/osteoporosis/OS350.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temp[0][0].min()\n",
    "import matplotlib.pyplot as plt\n",
    "index += 1\n",
    "# print(temp[1][index],temp[2][index])\n",
    "print((temp[0][index].numpy()*255).max().astype(np.uint8))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "print(str(temp[2][index]))\n",
    "# Plot the first image\n",
    "axs[0].imshow(((temp[0][index]+1)/2).permute(1, 2, 0))\n",
    "axs[0].set_title('Image 1')\n",
    "\n",
    "# Plot the second image\n",
    "axs[1].imshow(Image.open(temp[2][index]).convert('RGB'))\n",
    "axs[1].set_title('Image 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models here\n",
    "from resnetModel import ResNet50\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torcheval.metrics.functional import multiclass_f1_score,multiclass_confusion_matrix,multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from torch import mode\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from abc import ABC\n",
    "\n",
    "#FIXME identify bottleneck\n",
    "#FIXME clean up my fucking code ffs its so UGLY\n",
    "\n",
    "class ExperimentModel(L.LightningModule,ABC):\n",
    "\n",
    "    existingModels = []\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        ExperimentModel.existingModels.append(self)\n",
    "        super().__init__()\n",
    "\n",
    "        #init the models here in a subclass\n",
    "\n",
    "        self.num_class = 3\n",
    "        self.classWeight = torch.tensor([0.204, 0.052, 0.175],device='cuda')\n",
    "\n",
    "        self.valLog = []\n",
    "        self.epoch = []\n",
    "        self.valPreds = []\n",
    "        self.valLabels = []\n",
    "        self.valScore = []\n",
    "\n",
    "        self.bestValPreds = [[]]\n",
    "        self.bestValLabels = [[]]\n",
    "        self.bestValScore = []\n",
    "\n",
    "        self.dump = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward():\n",
    "        pass\n",
    "        \n",
    "    # def forward(self,input):\n",
    "    #     out = self.model(input)\n",
    "    #     return out\n",
    "        \n",
    "    def training_step(self,batch):\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "        self.dump.append([path,label])\n",
    "        loss = F.cross_entropy(output,label,weight=self.classWeight)\n",
    "        # print(loss)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", multiclass_accuracy(output.argmax(1),label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "\n",
    "        preds = output.argmax(1)\n",
    "        loss = F.cross_entropy(output,label)\n",
    "        self.valLabels.append(label)\n",
    "        self.valPreds.append(preds)\n",
    "        self.valScore.append(multiclass_f1_score(preds,label,num_classes=self.num_class,average = 'macro'))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_F1\", multiclass_f1_score(preds,label,num_classes=self.num_class,average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", multiclass_accuracy(preds,label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    \n",
    "    # def on_validation_epoch_end(self) -> None:\n",
    "    #     if len(self.valScore) == 2:\n",
    "    #         return None\n",
    "        \n",
    "    #     accuracy = torch.stack(self.valScore).mean()\n",
    "    #     self.bestValScore.append(accuracy)\n",
    "    #     self.bestValPreds.append(torch.cat(self.valPreds))\n",
    "    #     self.bestValLabels.append(torch.cat(self.valLabels))\n",
    "    #     print(f\"preds: {torch.cat(self.valPreds)}\\n labels: {torch.cat(self.valLabels)}\")\n",
    "    #     # self.log(\"val_acc_F1\", multiclass_f1_score(torch.cat(self.valPreds),torch.cat(self.valLabels),num_classes=self.num_class,average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "       \n",
    "    #     # print(f\"\\n Validation accuracy: {accuracy}\")\n",
    "    #     # print(f\"bestValScore: {self.bestValScore}\")\n",
    "    #     self.valPreds = []\n",
    "    #     self.valLabels = []\n",
    "    #     self.valScore = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        data,label = batch\n",
    "        return self(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCamTrack(ExperimentModel):\n",
    "    def __init__(self,vgg:torchvision.models.vgg.VGG) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = vgg.features[:36]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = vgg.classifier\n",
    "        self.classifier[6] = torch.nn.Linear(4096,3)\n",
    "\n",
    "        self.hookedImage = []\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)\n",
    "        \n",
    "    def forward(self,inTensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        # # register the hook\n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.flatten(1,-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "     \n",
    "    def visualize(self,dataloader:torch.utils.data.dataloader.DataLoader): #TODO FIX THIS for generalization\n",
    "        out,path = self.CAM(dataloader)\n",
    "        for x in range(len(out)):\n",
    "            self.visualizeAndWrite(out[x],path[x],666)\n",
    "    \n",
    "    def CAM(self,dataloader:torch.utils.data.dataloader.DataLoader):\n",
    "        self.eval()\n",
    "        img,label,path = next(iter(dataloader))\n",
    "        img = img.to(device = torch.device('cuda'))\n",
    "        heatmapList = []\n",
    "        for i in range(len(img)):\n",
    "            print(torch.unsqueeze(img[i],0).shape)\n",
    "            pred = self(torch.unsqueeze(img[i],0))\n",
    "            # get the gradient of the output with respect to the parameters of the model\n",
    "            print(pred.shape)\n",
    "            pred[:, label[i].item()].backward()\n",
    "\n",
    "            # pull the gradients out of the model\n",
    "            gradients = self.get_activations_gradient()\n",
    "\n",
    "            # pool the gradients across the channels\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "            # get the activations of the last convolutional layer\n",
    "            activations = self.get_activations(torch.unsqueeze(img[i],0)).detach() # DONT forget to apply image changes here too\n",
    "            print(activations.shape)\n",
    "            # weight the channels by corresponding gradients\n",
    "            for j in range(512):\n",
    "                activations[:, j, :, :] *= pooled_gradients[j]\n",
    "                \n",
    "            # average the channels of the activations\n",
    "            heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "            # relu on top of the heatmap\n",
    "            # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "            heatmap = np.maximum(heatmap.cpu(), 0)\n",
    "\n",
    "            # normalize the heatmap\n",
    "            heatmap /= torch.max(heatmap)\n",
    "\n",
    "            # draw the heatmap\n",
    "            heatmapList.append(heatmap)\n",
    "\n",
    "        return heatmapList,path\n",
    "\n",
    "    def visualizeAndWrite(self,out:torch.tensor,path:str,epoch=False):\n",
    "        if not epoch:\n",
    "            epoch = self.current_epoch\n",
    "            \n",
    "        img = cv2.imread(path)\n",
    "        heatmap = cv2.resize(out.numpy(), (img.shape[1], img.shape[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = heatmap * 0.4 + img\n",
    "        cv2.imwrite(rf'./visualizations/gradCam/{epoch}_{path.split(r\"/\")[-1]}', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\assaw\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGGModel(torchvision.models.vgg19(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentModel.existingModels[0].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentModel.existingModels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "for x in ExperimentModel.existingModels:\n",
    "    print(x)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # early_stopping = EarlyStopping(\n",
    "    #     monitor='val_loss',  # Metric to monitor\n",
    "    #     patience=5000,          # Number of epochs with no improvement after which training will be stopped\n",
    "    #     verbose=False,        # Verbosity mode\n",
    "    #     mode='min'           # Mode can be 'min', 'max', or 'auto'\n",
    "    # )\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=f\"{x.__class__.__name__}\")\n",
    "    \n",
    "\n",
    "    trainer = L.Trainer(max_epochs = 75,accelerator='gpu', devices='auto', precision='16-mixed',logger=logger)\n",
    "    trainer.fit(model=x,train_dataloaders=trainLoader,val_dataloaders=valLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\assaw\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\assaw\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\fabric\\utilities\\cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "model = VGGModel.load_from_checkpoint(r'tb_logs\\VGGModel\\version_4\\checkpoints\\epoch=25-step=962.ckpt',vgg = torchvision.models.vgg19(pretrained=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 0, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(valLoader))\n",
    "model(x[0].to('cuda')).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\assaw\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\assaw\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\fabric\\utilities\\cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n",
      "torch.Size([1, 3, 244, 244])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 512, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VGGModel.load_from_checkpoint(r'tb_logs\\VGGModel\\version_4\\checkpoints\\epoch=25-step=962.ckpt',vgg = torchvision.models.vgg19(pretrained=False))\n",
    "\n",
    "model.visualize(valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OP270.jpg'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 0, 2, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([2, 0, 0, 2, 0, 0, 2, 0], device='cuda:0'),\n",
       " tensor([0, 0, 2, 2, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 2, 0, 0], device='cuda:0'),\n",
       " tensor([0, 2, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 2, 2, 2, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 2, 0, 0, 0, 2, 0, 0], device='cuda:0'),\n",
       " tensor([0, 2, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 2, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 2, 0, 0, 2, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([2, 0, 0, 0, 2, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([2, 0, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 2, 0, 0], device='cuda:0'),\n",
       " tensor([0, 2, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 2, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([2, 0, 0, 0, 2, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 2, 2, 2, 2, 2, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 0, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 0, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 2, 2, 2, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 0, 2, 2, 0, 2, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 0, 0, 0, 2, 0, 2, 2], device='cuda:0'),\n",
       " tensor([2, 0], device='cuda:0'),\n",
       " tensor([1, 0, 1, 0, 2, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 2, 2, 2, 2, 2, 0, 2], device='cuda:0'),\n",
       " tensor([1, 2, 0, 1, 2, 0, 0, 2], device='cuda:0'),\n",
       " tensor([1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 0, 1, 2, 1, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 0, 2, 2, 0, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 0, 0, 2, 0, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 1, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 0, 1, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 0, 2, 0, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 0, 0, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 2, 2, 2, 0, 0, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1], device='cuda:0'),\n",
       " tensor([2, 0, 0, 0, 2, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 2, 0, 1, 2, 2, 0, 0], device='cuda:0'),\n",
       " tensor([2, 2, 1, 2, 2, 0, 0, 0], device='cuda:0'),\n",
       " tensor([2, 2, 0, 0, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 0, 0, 2, 0, 2, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 2, 0, 2, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 0, 0, 2, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 2, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 0, 0, 0, 0, 2, 1], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 0, 0, 0, 0, 2, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 1, 1, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 2, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 2, 2, 1, 2, 2, 0, 2], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 2, 0, 0, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 2, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 2, 0, 0, 0, 1], device='cuda:0'),\n",
       " tensor([0, 1, 0, 1, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 0, 0, 0, 2, 1], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 2, 2, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 2, 2, 1, 1, 1, 0], device='cuda:0'),\n",
       " tensor([1, 2, 1, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 1, 2, 1, 2, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 2, 2, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([2, 2, 1, 2, 2, 0, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 2, 1, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 0, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 2], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 2, 2, 1, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 0, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 1, 0, 0], device='cuda:0'),\n",
       " tensor([2, 2, 0, 1, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 0, 2, 0, 2], device='cuda:0'),\n",
       " tensor([1, 0, 1, 2, 2, 2, 1, 2], device='cuda:0'),\n",
       " tensor([2, 2, 1, 2, 2, 0, 2, 1], device='cuda:0'),\n",
       " tensor([1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 0, 1, 0, 2, 2], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 2, 1, 1, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 1, 2, 2, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n",
       " tensor([2, 2, 0, 1, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 1, 1, 0, 2, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 1, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([2, 2, 1, 2, 2, 0, 0, 2], device='cuda:0'),\n",
       " tensor([0, 2, 0, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 0, 0, 0, 2, 2], device='cuda:0'),\n",
       " tensor([0, 1], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 0, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 0, 1, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 0, 1, 0, 1, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 0, 1, 2, 2, 0, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 2, 0, 1, 0, 1, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 2, 1, 2], device='cuda:0'),\n",
       " tensor([0, 0, 0, 1, 1, 1, 1, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 0, 0, 1], device='cuda:0'),\n",
       " tensor([0, 1, 1, 1, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 0, 0, 0, 2, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 2, 2, 2, 1, 2], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 1, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 1, 2, 1, 2], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 2, 1, 1, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 0, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 2, 1, 2, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 1, 1, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 2, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 1, 2, 1], device='cuda:0'),\n",
       " tensor([1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 2, 1, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 0, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 0, 1, 0, 0, 1, 0, 2], device='cuda:0'),\n",
       " tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 0, 1, 1, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 0, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 2, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 0, 1, 2, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n",
       " tensor([0, 2, 1, 1, 1, 2, 0, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 0, 1, 1, 2, 1], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 1, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 0, 1, 0, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 0, 2, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 0, 0, 2, 1], device='cuda:0'),\n",
       " tensor([0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 2], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 2, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 1, 1, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 0, 1, 1, 2, 1], device='cuda:0'),\n",
       " tensor([1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 2, 1, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 0, 2, 2, 2, 0, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 0, 0, 2, 2, 2], device='cuda:0'),\n",
       " tensor([1, 2, 1, 2, 0, 2, 1, 2], device='cuda:0'),\n",
       " tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 0, 0, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 0, 1, 2, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 0, 0, 0, 2, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 2, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 2, 1, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 0, 0, 0, 0, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 0, 1, 2, 2], device='cuda:0'),\n",
       " tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 2, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 2, 1, 1, 1, 2, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 1, 1, 1, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 2, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1], device='cuda:0'),\n",
       " tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n",
       " tensor([0, 2, 1, 1, 2, 2, 0, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([1, 1, 0, 0, 1, 1, 2, 2], device='cuda:0'),\n",
       " tensor([2, 1, 1, 1, 0, 1, 1, 2], device='cuda:0'),\n",
       " tensor([1, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n",
       " tensor([0, 0, 1, 1, 0, 1, 2, 2], device='cuda:0'),\n",
       " tensor([1, 1, 1, 0, 1, 0, 2, 1], device='cuda:0'),\n",
       " tensor([1, 0], device='cuda:0')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExperimentModel.existingModels[0].valPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# [[y.argmax().item() for y in w] for w in x.bestValPreds]\n",
    "# ([1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 2, 1,\n",
    "#          1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n",
    "# [[y.argmax().item() for y in w] for w in x.bestValPreds]\n",
    "preds = torch.tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
    "        1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 2, 2, 1, 1,\n",
    "        1, 1])\n",
    "labels = torch.tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 2, 1, 1, 1,\n",
    "        1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 0, 0, 2, 2, 0, 1, 1, 2, 2, 1, 1, 0, 2,\n",
    "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
    "        1, 1])\n",
    "index = 50\n",
    "cm = confusion_matrix(preds,labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "# plt.plot(confusion_matrix([[y.argmax().item() for y in w] for w in x.bestValPreds][index],x.bestValLabels[1].cpu()))\n",
    "print(classification_report(preds,labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,_,_ = next(iter(trainLoader))\n",
    "x = model.features(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.flatten(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.classifier(x.flatten(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze(img[0],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4603, -0.0584,  0.0571]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 512, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "vgg19.eval()\n",
    "img,lab,path = next(iter(trainLoader))\n",
    "pred = vgg19(torch.unsqueeze(img[0],0))\n",
    "print(pred)\n",
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 1].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg19.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg19.get_activations(torch.unsqueeze(img[0],0)).detach()\n",
    "print(activations.shape)\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(out[1][0])\n",
    "heatmap = cv2.resize(out[0][0].numpy(), (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./test.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\assaw\\\\Documents\\\\c_stuff\\\\Python\\\\machine learning\\\\ISAIConference\\\\testIm/osteopenia/OP270.jpg'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"img.jpg\",superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.19.0', \"vgg19\",{\"num_classes\":3}, pretrained=True, )\n",
    "model.classifier[6] = torch.nn.Linear(4096,3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.cuda.empty_cache()\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.204, 0.052, 0.175],device='cuda'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "accHistory = []\n",
    "lossHistory = []\n",
    "valAccHistory = []\n",
    "valLabs = []\n",
    "valPreds = []\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = []\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for inputs, labels, _ in trainLoader:\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "        running_accuracy.append(accuracy)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1} - Loss: {running_loss / len(trainLoader)}\")\n",
    "    print(F\"Accuracy: {sum(running_accuracy)/len(running_accuracy)}\")\n",
    "    accHistory.append(sum(running_accuracy)/len(running_accuracy))\n",
    "    lossHistory.append(running_loss / len(trainLoader))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        runningValAccHistory = []\n",
    "        runningValLabs = []\n",
    "        runningValPreds = []\n",
    "        for inputs, labels, _ in valLoader:\n",
    "\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the predicted labels\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "\n",
    "            runningValAccHistory.append(accuracy)\n",
    "            runningValLabs.append(labels)\n",
    "            runningValPreds.append(predicted_labels)\n",
    "\n",
    "        # print(f\"Validation Loss: {loss.item()}\")\n",
    "        valPreds.append(runningValPreds)\n",
    "        valLabs.append(runningValLabs)\n",
    "        print(f\"Validation Accuracy: {sum(runningValAccHistory)/len(valLoader)}\")\n",
    "        valAccHistory.append(sum(runningValAccHistory)/len(valLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "idx = 34\n",
    "predsTest = torch.cat(valPreds[idx-1])\n",
    "labelsTest = torch.cat(valLabs[idx-1])\n",
    "print(valAccHistory[idx-1])\n",
    "print(classification_report(predsTest.cpu(),labelsTest.cpu()))\n",
    "cm= confusion_matrix(predsTest.cpu(),labelsTest.cpu(),normalize='true')\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f',)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valAccHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input , label, _ = next(iter(valLoader))\n",
    "# Move the inputs and labels to the device\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "predicted_labels = torch.argmax(outputs, dim=1)\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with the data\n",
    "df = pd.DataFrame({'Epoch': range(len(accHistory)), 'Accuracy': accHistory, 'Loss': lossHistory, 'Validation Accuracy': valAccHistory})\n",
    "\n",
    "# Create the line plot\n",
    "sns.relplot(data=df, x='Epoch', y='Accuracy', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Loss', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Validation Accuracy', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnetClassic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "label = []\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, _ in valLoader:\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label = labels\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute the predicted labels\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.argmax(1))\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
