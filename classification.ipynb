{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from transformers import AutoImageProcessor, ResNetForImageClassification,ResNetConfig\n",
    "import torch\n",
    "from abc import ABC,abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###DATASET PREP###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r\".\\testIm\"\n",
    "trainPathList = []\n",
    "trainLabelList = []\n",
    "trainDirList = os.listdir(trainPath)[:3]\n",
    "for idx, x in enumerate(trainDirList):\n",
    "    for xx in os.listdir(f\"{trainPath}/{x}\"):\n",
    "        trainPathList.append(f\"{trainPath}/{x}/{xx}\")\n",
    "        trainLabelList.append(idx)\n",
    "        \n",
    "valPath = r\".\\ValidationSet\"\n",
    "valPathList = []\n",
    "valLabelList = []\n",
    "valDirList = os.listdir(valPath)[:3]\n",
    "for idx, x in enumerate(valDirList):\n",
    "    for xx in os.listdir(f\"{valPath}/{x}\"):\n",
    "        valPathList.append(f\"{valPath}/{x}/{xx}\")\n",
    "        valLabelList.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "normal: 10\n",
      "1\n",
      "osteopenia: 10\n",
      "2\n",
      "osteoporosis: 10\n"
     ]
    }
   ],
   "source": [
    "for idx,x in enumerate(valDirList):\n",
    "    print(idx)\n",
    "    print(f\"{x}: {len(os.listdir(f'{valPath}/{x}'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\testIm/normal/N10.jpg',\n",
       " '.\\\\testIm/normal/N100.jpg',\n",
       " '.\\\\testIm/normal/N101.jpg',\n",
       " '.\\\\testIm/normal/N11.jpg',\n",
       " '.\\\\testIm/normal/N110.jpg',\n",
       " '.\\\\testIm/normal/N111.jpg',\n",
       " '.\\\\testIm/normal/N120.jpg',\n",
       " '.\\\\testIm/normal/N121.jpg',\n",
       " '.\\\\testIm/normal/N130.jpg',\n",
       " '.\\\\testIm/normal/N131.jpg',\n",
       " '.\\\\testIm/normal/N140.jpg',\n",
       " '.\\\\testIm/normal/N141.jpg',\n",
       " '.\\\\testIm/normal/N150.jpg',\n",
       " '.\\\\testIm/normal/N151.jpg',\n",
       " '.\\\\testIm/normal/N170.jpg',\n",
       " '.\\\\testIm/normal/N171.jpg',\n",
       " '.\\\\testIm/normal/N180.jpg',\n",
       " '.\\\\testIm/normal/N190.jpg',\n",
       " '.\\\\testIm/normal/N191.jpg',\n",
       " '.\\\\testIm/normal/N20.jpg',\n",
       " '.\\\\testIm/normal/N200.jpg',\n",
       " '.\\\\testIm/normal/N201.jpg',\n",
       " '.\\\\testIm/normal/N210.jpg',\n",
       " '.\\\\testIm/normal/N211.jpg',\n",
       " '.\\\\testIm/normal/N230.jpg',\n",
       " '.\\\\testIm/normal/N231.jpg',\n",
       " '.\\\\testIm/normal/N240.jpg',\n",
       " '.\\\\testIm/normal/N250.jpg',\n",
       " '.\\\\testIm/normal/N260.jpg',\n",
       " '.\\\\testIm/normal/N270.jpg',\n",
       " '.\\\\testIm/normal/N290.jpg',\n",
       " '.\\\\testIm/normal/N30.jpg',\n",
       " '.\\\\testIm/normal/N300.jpg',\n",
       " '.\\\\testIm/normal/N301.jpg',\n",
       " '.\\\\testIm/normal/N31.jpg',\n",
       " '.\\\\testIm/normal/N310.jpg',\n",
       " '.\\\\testIm/normal/N320.jpg',\n",
       " '.\\\\testIm/normal/N330.jpg',\n",
       " '.\\\\testIm/normal/N340.jpg',\n",
       " '.\\\\testIm/normal/N350.jpg',\n",
       " '.\\\\testIm/normal/N360.jpg',\n",
       " '.\\\\testIm/normal/N40.jpg',\n",
       " '.\\\\testIm/normal/N41.jpg',\n",
       " '.\\\\testIm/normal/N50.jpg',\n",
       " '.\\\\testIm/normal/N51.jpg',\n",
       " '.\\\\testIm/normal/N61.jpg',\n",
       " '.\\\\testIm/normal/N62.jpg',\n",
       " '.\\\\testIm/normal/N70.jpg',\n",
       " '.\\\\testIm/normal/N71.jpg',\n",
       " '.\\\\testIm/normal/N80.jpg',\n",
       " '.\\\\testIm/normal/N81.jpg',\n",
       " '.\\\\testIm/normal/N90.jpg',\n",
       " '.\\\\testIm/normal/N91.jpg',\n",
       " '.\\\\testIm/osteopenia/OP10.jpg',\n",
       " '.\\\\testIm/osteopenia/OP100.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1000.jpg',\n",
       " '.\\\\testIm/osteopenia/OP101.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1020.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1040.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1060.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1070.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1071.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1090.jpg',\n",
       " '.\\\\testIm/osteopenia/OP11.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1100.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1110.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1130.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1140.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1150.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1160.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1170.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1180.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1190.jpg',\n",
       " '.\\\\testIm/osteopenia/OP120.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1200.jpg',\n",
       " '.\\\\testIm/osteopenia/OP121.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1210.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1220.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1221.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1230.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1231.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1240.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1250.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1260.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1270.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1280.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1290.jpg',\n",
       " '.\\\\testIm/osteopenia/OP130.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1300.jpg',\n",
       " '.\\\\testIm/osteopenia/OP131.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1310.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1320.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1330.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1340.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1350.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1360.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1370.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1380.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1390.jpg',\n",
       " '.\\\\testIm/osteopenia/OP140.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1400.jpg',\n",
       " '.\\\\testIm/osteopenia/OP141.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1410.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1420.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1430.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1440.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1460.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1470.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1480.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1490.jpg',\n",
       " '.\\\\testIm/osteopenia/OP150.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1500.jpg',\n",
       " '.\\\\testIm/osteopenia/OP151.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1510.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1520.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1530.jpg',\n",
       " '.\\\\testIm/osteopenia/OP1540.jpg',\n",
       " '.\\\\testIm/osteopenia/OP161.jpg',\n",
       " '.\\\\testIm/osteopenia/OP162.jpg',\n",
       " '.\\\\testIm/osteopenia/OP170.jpg',\n",
       " '.\\\\testIm/osteopenia/OP171.jpg',\n",
       " '.\\\\testIm/osteopenia/OP180.jpg',\n",
       " '.\\\\testIm/osteopenia/OP181.jpg',\n",
       " '.\\\\testIm/osteopenia/OP190.jpg',\n",
       " '.\\\\testIm/osteopenia/OP191.jpg',\n",
       " '.\\\\testIm/osteopenia/OP200.jpg',\n",
       " '.\\\\testIm/osteopenia/OP211.jpg',\n",
       " '.\\\\testIm/osteopenia/OP230.jpg',\n",
       " '.\\\\testIm/osteopenia/OP231.jpg',\n",
       " '.\\\\testIm/osteopenia/OP240.jpg',\n",
       " '.\\\\testIm/osteopenia/OP241.jpg',\n",
       " '.\\\\testIm/osteopenia/OP250.jpg',\n",
       " '.\\\\testIm/osteopenia/OP251.jpg',\n",
       " '.\\\\testIm/osteopenia/OP260.jpg',\n",
       " '.\\\\testIm/osteopenia/OP261.jpg',\n",
       " '.\\\\testIm/osteopenia/OP270.jpg',\n",
       " '.\\\\testIm/osteopenia/OP271.jpg',\n",
       " '.\\\\testIm/osteopenia/OP280.jpg',\n",
       " '.\\\\testIm/osteopenia/OP281.jpg',\n",
       " '.\\\\testIm/osteopenia/OP290.jpg',\n",
       " '.\\\\testIm/osteopenia/OP291.jpg',\n",
       " '.\\\\testIm/osteopenia/OP30.jpg',\n",
       " '.\\\\testIm/osteopenia/OP300.jpg',\n",
       " '.\\\\testIm/osteopenia/OP301.jpg',\n",
       " '.\\\\testIm/osteopenia/OP31.jpg',\n",
       " '.\\\\testIm/osteopenia/OP310.jpg',\n",
       " '.\\\\testIm/osteopenia/OP311.jpg',\n",
       " '.\\\\testIm/osteopenia/OP320.jpg',\n",
       " '.\\\\testIm/osteopenia/OP321.jpg',\n",
       " '.\\\\testIm/osteopenia/OP330.jpg',\n",
       " '.\\\\testIm/osteopenia/OP331.jpg',\n",
       " '.\\\\testIm/osteopenia/OP340.jpg',\n",
       " '.\\\\testIm/osteopenia/OP341.jpg',\n",
       " '.\\\\testIm/osteopenia/OP350.jpg',\n",
       " '.\\\\testIm/osteopenia/OP351.jpg',\n",
       " '.\\\\testIm/osteopenia/OP360.jpg',\n",
       " '.\\\\testIm/osteopenia/OP361.jpg',\n",
       " '.\\\\testIm/osteopenia/OP370.jpg',\n",
       " '.\\\\testIm/osteopenia/OP371.jpg',\n",
       " '.\\\\testIm/osteopenia/OP40.jpg',\n",
       " '.\\\\testIm/osteopenia/OP400.jpg',\n",
       " '.\\\\testIm/osteopenia/OP401.jpg',\n",
       " '.\\\\testIm/osteopenia/OP41.jpg',\n",
       " '.\\\\testIm/osteopenia/OP410.jpg',\n",
       " '.\\\\testIm/osteopenia/OP411.jpg',\n",
       " '.\\\\testIm/osteopenia/OP430.jpg',\n",
       " '.\\\\testIm/osteopenia/OP431.jpg',\n",
       " '.\\\\testIm/osteopenia/OP450.jpg',\n",
       " '.\\\\testIm/osteopenia/OP451.jpg',\n",
       " '.\\\\testIm/osteopenia/OP460.jpg',\n",
       " '.\\\\testIm/osteopenia/OP461.jpg',\n",
       " '.\\\\testIm/osteopenia/OP470.jpg',\n",
       " '.\\\\testIm/osteopenia/OP471.jpg',\n",
       " '.\\\\testIm/osteopenia/OP480.jpg',\n",
       " '.\\\\testIm/osteopenia/OP481.jpg',\n",
       " '.\\\\testIm/osteopenia/OP490.jpg',\n",
       " '.\\\\testIm/osteopenia/OP491.jpg',\n",
       " '.\\\\testIm/osteopenia/OP50.jpg',\n",
       " '.\\\\testIm/osteopenia/OP500.jpg',\n",
       " '.\\\\testIm/osteopenia/OP501.jpg',\n",
       " '.\\\\testIm/osteopenia/OP51.jpg',\n",
       " '.\\\\testIm/osteopenia/OP510.jpg',\n",
       " '.\\\\testIm/osteopenia/OP511.jpg',\n",
       " '.\\\\testIm/osteopenia/OP520.jpg',\n",
       " '.\\\\testIm/osteopenia/OP530.jpg',\n",
       " '.\\\\testIm/osteopenia/OP531.jpg',\n",
       " '.\\\\testIm/osteopenia/OP540.jpg',\n",
       " '.\\\\testIm/osteopenia/OP541.jpg',\n",
       " '.\\\\testIm/osteopenia/OP550.jpg',\n",
       " '.\\\\testIm/osteopenia/OP551.jpg',\n",
       " '.\\\\testIm/osteopenia/OP561.jpg',\n",
       " '.\\\\testIm/osteopenia/OP570.jpg',\n",
       " '.\\\\testIm/osteopenia/OP571.jpg',\n",
       " '.\\\\testIm/osteopenia/OP580.jpg',\n",
       " '.\\\\testIm/osteopenia/OP590.jpg',\n",
       " '.\\\\testIm/osteopenia/OP591.jpg',\n",
       " '.\\\\testIm/osteopenia/OP60.jpg',\n",
       " '.\\\\testIm/osteopenia/OP600.jpg',\n",
       " '.\\\\testIm/osteopenia/OP602.jpg',\n",
       " '.\\\\testIm/osteopenia/OP61.jpg',\n",
       " '.\\\\testIm/osteopenia/OP610.jpg',\n",
       " '.\\\\testIm/osteopenia/OP611.jpg',\n",
       " '.\\\\testIm/osteopenia/OP620.jpg',\n",
       " '.\\\\testIm/osteopenia/OP621.jpg',\n",
       " '.\\\\testIm/osteopenia/OP630.jpg',\n",
       " '.\\\\testIm/osteopenia/OP631.jpg',\n",
       " '.\\\\testIm/osteopenia/OP640.jpg',\n",
       " '.\\\\testIm/osteopenia/OP641.jpg',\n",
       " '.\\\\testIm/osteopenia/OP650.jpg',\n",
       " '.\\\\testIm/osteopenia/OP651.jpg',\n",
       " '.\\\\testIm/osteopenia/OP660.jpg',\n",
       " '.\\\\testIm/osteopenia/OP661.jpg',\n",
       " '.\\\\testIm/osteopenia/OP670.jpg',\n",
       " '.\\\\testIm/osteopenia/OP671.jpg',\n",
       " '.\\\\testIm/osteopenia/OP680.jpg',\n",
       " '.\\\\testIm/osteopenia/OP681.jpg',\n",
       " '.\\\\testIm/osteopenia/OP690.jpg',\n",
       " '.\\\\testIm/osteopenia/OP691.jpg',\n",
       " '.\\\\testIm/osteopenia/OP70.jpg',\n",
       " '.\\\\testIm/osteopenia/OP700.jpg',\n",
       " '.\\\\testIm/osteopenia/OP701.jpg',\n",
       " '.\\\\testIm/osteopenia/OP71.jpg',\n",
       " '.\\\\testIm/osteopenia/OP710.jpg',\n",
       " '.\\\\testIm/osteopenia/OP711.jpg',\n",
       " '.\\\\testIm/osteopenia/OP720.jpg',\n",
       " '.\\\\testIm/osteopenia/OP730.jpg',\n",
       " '.\\\\testIm/osteopenia/OP731.jpg',\n",
       " '.\\\\testIm/osteopenia/OP740.jpg',\n",
       " '.\\\\testIm/osteopenia/OP741.jpg',\n",
       " '.\\\\testIm/osteopenia/OP750.jpg',\n",
       " '.\\\\testIm/osteopenia/OP751.jpg',\n",
       " '.\\\\testIm/osteopenia/OP760.jpg',\n",
       " '.\\\\testIm/osteopenia/OP762.jpg',\n",
       " '.\\\\testIm/osteopenia/OP770.jpg',\n",
       " '.\\\\testIm/osteopenia/OP771.jpg',\n",
       " '.\\\\testIm/osteopenia/OP780.jpg',\n",
       " '.\\\\testIm/osteopenia/OP781.jpg',\n",
       " '.\\\\testIm/osteopenia/OP790.jpg',\n",
       " '.\\\\testIm/osteopenia/OP791.jpg',\n",
       " '.\\\\testIm/osteopenia/OP80.jpg',\n",
       " '.\\\\testIm/osteopenia/OP800.jpg',\n",
       " '.\\\\testIm/osteopenia/OP801.jpg',\n",
       " '.\\\\testIm/osteopenia/OP81.jpg',\n",
       " '.\\\\testIm/osteopenia/OP810.jpg',\n",
       " '.\\\\testIm/osteopenia/OP811.jpg',\n",
       " '.\\\\testIm/osteopenia/OP820.jpg',\n",
       " '.\\\\testIm/osteopenia/OP821.jpg',\n",
       " '.\\\\testIm/osteopenia/OP830.jpg',\n",
       " '.\\\\testIm/osteopenia/OP831.jpg',\n",
       " '.\\\\testIm/osteopenia/OP840.jpg',\n",
       " '.\\\\testIm/osteopenia/OP841.jpg',\n",
       " '.\\\\testIm/osteopenia/OP850.jpg',\n",
       " '.\\\\testIm/osteopenia/OP851.jpg',\n",
       " '.\\\\testIm/osteopenia/OP860.jpg',\n",
       " '.\\\\testIm/osteopenia/OP861.jpg',\n",
       " '.\\\\testIm/osteopenia/OP870.jpg',\n",
       " '.\\\\testIm/osteopenia/OP871.jpg',\n",
       " '.\\\\testIm/osteopenia/OP882.jpg',\n",
       " '.\\\\testIm/osteopenia/OP885.jpg',\n",
       " '.\\\\testIm/osteopenia/OP890.jpg',\n",
       " '.\\\\testIm/osteopenia/OP891.jpg',\n",
       " '.\\\\testIm/osteopenia/OP90.jpg',\n",
       " '.\\\\testIm/osteopenia/OP900.jpg',\n",
       " '.\\\\testIm/osteopenia/OP901.jpg',\n",
       " '.\\\\testIm/osteopenia/OP91.jpg',\n",
       " '.\\\\testIm/osteopenia/OP910.jpg',\n",
       " '.\\\\testIm/osteopenia/OP911.jpg',\n",
       " '.\\\\testIm/osteopenia/OP920.jpg',\n",
       " '.\\\\testIm/osteopenia/OP921.jpg',\n",
       " '.\\\\testIm/osteopenia/OP930.jpg',\n",
       " '.\\\\testIm/osteopenia/OP931.jpg',\n",
       " '.\\\\testIm/osteopenia/OP940.jpg',\n",
       " '.\\\\testIm/osteopenia/OP950.jpg',\n",
       " '.\\\\testIm/osteopenia/OP960.jpg',\n",
       " '.\\\\testIm/osteopenia/OP961.jpg',\n",
       " '.\\\\testIm/osteopenia/OP970.jpg',\n",
       " '.\\\\testIm/osteopenia/OP980.jpg',\n",
       " '.\\\\testIm/osteopenia/OP990.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS10.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS100.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS101.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS11.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS110.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS111.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS120.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS121.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS130.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS131.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS140.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS141.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS150.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS151.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS160.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS161.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS170.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS171.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS180.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS181.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS190.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS191.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS20.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS200.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS201.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS21.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS210.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS211.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS220.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS221.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS230.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS240.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS241.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS250.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS260.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS270.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS280.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS290.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS291.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS300.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS310.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS320.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS330.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS340.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS350.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS360.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS370.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS380.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS381.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS390.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS40.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS400.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS41.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS410.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS420.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS430.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS440.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS450.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS460.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS461.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS470.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS480.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS490.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS50.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS51.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS60.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS61.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS70.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS71.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS80.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS81.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS90.jpg',\n",
       " '.\\\\testIm/osteoporosis/OS91.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPathList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(2180, 2660)': 1,\n",
       " '(1024, 1024)': 1,\n",
       " '(2430, 1994)': 23,\n",
       " '(2386, 1994)': 1,\n",
       " '(1994, 2430)': 1,\n",
       " '(2430, 1910)': 1,\n",
       " '(2402, 1994)': 1,\n",
       " '(2378, 1994)': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "imageSizes = {}\n",
    "for x in valPathList:\n",
    "    img = Image.open(x).size\n",
    "    try:\n",
    "        imageSizes[str(img)] = imageSizes[str(img)] + 1\n",
    "    except KeyError:\n",
    "        imageSizes[str(img)] = 1\n",
    "imageSizes #varied image sizes, have to resize to 1024,1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as vF\n",
    "\n",
    "class OsteoTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, itemsPath:list, labels:list, transform=None, std = False, mean = False): #mean on if mean needs to be scaled, same goes for std\n",
    "        \n",
    "        self.itemsPath = itemsPath\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itemsPath)\n",
    "\n",
    "    def __getitem__(self,idx)->tuple[Image.Image,int]:\n",
    "        image = Image.open(self.itemsPath[idx]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "        \n",
    "        image.to(device = torch.device('cuda'))\n",
    "\n",
    "        return image, self.labels[idx], self.itemsPath[idx]          \n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Resize((224,224)),\n",
    "                                            # torchvision.transforms.CenterCrop((224,224)),\n",
    "                                            torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                                            ])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 86,  89, 106])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "#inits dataset and dataloader + resamples training data to balance classes\n",
    "osteoDataset = OsteoTorchDataset(trainPathList,trainLabelList,transform,std=False,mean=False)      \n",
    "train,val = torch.utils.data.random_split(osteoDataset,[0.8,0.2])#MAY BUG\n",
    "trainLabels = [y for x,y,z in train]\n",
    "unique_elements, counts = torch.unique(torch.tensor(trainLabels), return_counts=True)\n",
    "sampleWeights = 1. / counts.float() #I HAVE NO IDEA WHY THIS WORKS BUT IT DOES\n",
    "# MORAL OF THE STORY: FOLLOW THE FUCKING TUTORIAL DONT TRY CHANGING SHIT ON YOUR OWN ***EVEN IF THE DOCUMENTATION SAYS YOU SHOULD***\n",
    "trainSampler = WeightedRandomSampler(weights=[sampleWeights[x] for x in trainLabels],num_samples=len(train),replacement=True)\n",
    "\n",
    "trainLoader = DataLoader(train, batch_size = 8,shuffle=False,num_workers=0,sampler=trainSampler)\n",
    "valLoader = DataLoader(val, batch_size = 16,shuffle=True,num_workers=0)\n",
    "\n",
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in trainLoader]), return_counts=True)#delete this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 42, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements, counts = torch.unique(torch.cat([x for y,x,z in valLoader]), return_counts=True)#delete this\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(trainLoader))\n",
    "temp[0][0].max()\n",
    "index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "C:\\Users\\assaw\\Documents\\c_stuff\\Python\\machine learning\\ISAIConference\\testIm/osteopenia/OP530.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temp[0][0].min()\n",
    "import matplotlib.pyplot as plt\n",
    "index += 1\n",
    "# print(temp[1][index],temp[2][index])\n",
    "print((temp[0][index].numpy()*255).max().astype(np.uint8))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "print(str(temp[2][index]))\n",
    "# Plot the first image\n",
    "axs[0].imshow(((temp[0][index]+1)/2).permute(1, 2, 0))\n",
    "axs[0].set_title('Image 1')\n",
    "\n",
    "# Plot the second image\n",
    "axs[1].imshow(Image.open(temp[2][index]).convert('RGB'))\n",
    "axs[1].set_title('Image 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models here\n",
    "import sklearn.metrics\n",
    "from resnetModel import ResNet50\n",
    "import sklearn\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torcheval.metrics.functional import multiclass_f1_score,multiclass_confusion_matrix,multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from torch import mode\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from abc import ABC\n",
    "\n",
    "#FIXME identify bottleneck\n",
    "#FIXME clean up my fucking code ffs its so UGLY\n",
    "\n",
    "class ExperimentModel(L.LightningModule,ABC):\n",
    "\n",
    "    existingModels = []\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        ExperimentModel.existingModels.append(self)\n",
    "        super().__init__()\n",
    "\n",
    "        #init the models here in a subclass\n",
    "\n",
    "        self.num_class = 3\n",
    "        self.classWeight = torch.tensor([0.204, 0.052, 0.175],device='cuda')\n",
    "\n",
    "        self.valLog = []\n",
    "        self.epoch = []\n",
    "        self.valPreds = []\n",
    "        self.valLabels = []\n",
    "        self.valScore = []\n",
    "\n",
    "        self.bestValPreds = [[]]\n",
    "        self.bestValLabels = [[]]\n",
    "        self.bestValScore = []\n",
    "\n",
    "        self.dump = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward():\n",
    "        pass\n",
    "    \n",
    "    def training_step(self,batch):\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "        self.dump.append([path,label])\n",
    "        loss = F.cross_entropy(output,label,weight=self.classWeight)\n",
    "        # print(loss)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", multiclass_accuracy(output.argmax(1),label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        data,label,path = batch\n",
    "        output = self(data)\n",
    "\n",
    "        preds = output.argmax(1)\n",
    "        loss = F.cross_entropy(output,label)\n",
    "        self.valLabels.append(label)\n",
    "        self.valPreds.append(preds)\n",
    "        self.valScore.append(sklearn.metrics.f1_score(label.cpu(),preds.cpu(),labels = range(self.num_class),average = 'macro'))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_F1\", sklearn.metrics.f1_score(label.cpu(),preds.cpu(),labels = range(self.num_class),average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", multiclass_accuracy(preds,label,num_classes=self.num_class), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    \n",
    "    # def on_validation_epoch_end(self) -> None:\n",
    "    #     if len(self.valScore) == 2:\n",
    "    #         return None\n",
    "        \n",
    "    #     accuracy = torch.stack(self.valScore).mean()\n",
    "    #     self.bestValScore.append(accuracy)\n",
    "    #     self.bestValPreds.append(torch.cat(self.valPreds))\n",
    "    #     self.bestValLabels.append(torch.cat(self.valLabels))\n",
    "    #     print(f\"preds: {torch.cat(self.valPreds)}\\n labels: {torch.cat(self.valLabels)}\")\n",
    "    #     # self.log(\"val_acc_F1\", multiclass_f1_score(torch.cat(self.valPreds),torch.cat(self.valLabels),num_classes=self.num_class,average = 'macro'), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "       \n",
    "    #     # print(f\"\\n Validation accuracy: {accuracy}\")\n",
    "    #     # print(f\"bestValScore: {self.bestValScore}\")\n",
    "    #     self.valPreds = []\n",
    "    #     self.valLabels = []\n",
    "    #     self.valScore = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        data,label = batch\n",
    "        return self(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "\n",
    "class GradCamTrack(ExperimentModel): #Class for GradCam visualization, should be subclassed by the model to be visualized with a new init and a forward + hook\n",
    "    \n",
    "    def __init__(self,) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gradients = None\n",
    "        self.cachedActivation = None\n",
    "\n",
    "    # cachedActivation is no longer needed, but kept for legacy purposes\n",
    "    def activations_hook(self, grad, imageActivation = None):\n",
    "        if imageActivation != None:\n",
    "            self.cachedActivation = imageActivation\n",
    "        self.gradients = grad\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)\n",
    "     \n",
    "    # Runs CAM and overlays the image\n",
    "    # this is the function to call for visualization\n",
    "    def visualize(self,dataloader:torch.utils.data.dataloader.DataLoader): #TODO FIX THIS for generalization\n",
    "        out,path,label = self.CAM(dataloader)\n",
    "        for i in range(len(out)):\n",
    "            self.visualizeAndWrite(out[i],path[i],label[i])\n",
    "        return out,path\n",
    "    \n",
    "    # Visualizes the Gradients of the last conv layer of model\n",
    "    # can take in torch dataloader or list of [img],[label],[path]\n",
    "    def CAM(self,dataloader:torch.utils.data.dataloader.DataLoader):\n",
    "        self.eval()\n",
    "        if isinstance(dataloader,torch.utils.data.dataloader.DataLoader):\n",
    "            img,label,path = next(iter(dataloader))\n",
    "\n",
    "        else:\n",
    "            img,label,path = dataloader\n",
    "\n",
    "        img = img.to(device = torch.device('cuda'))\n",
    "        heatmapList = []\n",
    "        for i in range(len(img)):\n",
    "            pred = self(torch.unsqueeze(img[i],0))\n",
    "            # get the gradient of the output with respect to the parameters of the model\n",
    "            pred[:, label[i].item()].backward()\n",
    "\n",
    "            # pull the gradients out of the model\n",
    "            gradients = self.get_activations_gradient()\n",
    "\n",
    "            # pool the gradients across the channels\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "            # get the activations of the last convolutional layer\n",
    "            if self.cachedActivation != None:\n",
    "                activations = self.cachedActivation.detach()\n",
    "                print(activations - self.get_activations(torch.unsqueeze(img[i],0)).detach())\n",
    "                print(f\"cached:{activations.shape}\")\n",
    "            else:\n",
    "                activations = self.get_activations(torch.unsqueeze(img[i],0)).detach() # DONT forget to apply image changes here too\n",
    "                print(f\"not cached:{activations.shape}\")\n",
    "            # weight the channels by corresponding gradients\n",
    "            print(f\"pooled shape: {pooled_gradients.shape}\")\n",
    "            for j in range(pooled_gradients.shape[0]):\n",
    "                activations[:, j, :, :] *= pooled_gradients[j]\n",
    "                \n",
    "            # average the channels of the activations\n",
    "            heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "            print(heatmap.shape)\n",
    "\n",
    "            # relu on top of the heatmap\n",
    "            # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "            heatmap = np.maximum(heatmap.detach().cpu(), 0)\n",
    "\n",
    "            # normalize the heatmap\n",
    "            heatmap /= torch.max(heatmap)\n",
    "\n",
    "            # draw the heatmap\n",
    "            heatmapList.append(heatmap)\n",
    "            print(heatmap.shape)\n",
    "\n",
    "        return heatmapList,path,label\n",
    "    \n",
    "\n",
    "    #writes files to disk for visualization, format: model_epoch_label_pred/image.jpg\n",
    "    def visualizeAndWrite(self,out:torch.tensor,path:str,label:str,epoch=False): #TODO Implement this with tensorboard\n",
    "        if not epoch:\n",
    "            epoch = self.current_epoch\n",
    "\n",
    "        labelDict = {0:'N',1:'OP',2:'OS'}\n",
    "            \n",
    "        img = cv2.imread(path)\n",
    "        heatmap = cv2.resize(out.numpy(), (img.shape[1], img.shape[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = heatmap * 0.4 + img\n",
    "        match = re.findall(r\"[A-Z,a-z]*\",path)[-1]\n",
    "        path = re.sub(r\"[A-Z,a-z]*\",labelDict[match],path)\n",
    "        cv2.imwrite(rf'./visualizations/gradCam/{self.__class__.__name__}_{epoch}__{str(label)}_{path.split(r\"/\")[-1]}', superimposed_img)\n",
    "\n",
    "\n",
    "class VGGModel(GradCamTrack):\n",
    "    def __init__(self,vgg:torchvision.models.vgg.VGG) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = vgg.features[:36]\n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = vgg.classifier\n",
    "        self.classifier[6] = torch.nn.Linear(4096,self.num_class)\n",
    "\n",
    "\n",
    "    def forward(self,inTensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        # # register the hook\n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.flatten(1,-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "import resnetModel\n",
    "\n",
    "class ResnetModel(GradCamTrack):\n",
    "    def __init__(self,resnet:torchvision.models.resnet.ResNet) -> None:\n",
    "        super().__init__()\n",
    "        self.features_conv = torch.nn.Sequential(*[x for x in resnet.children()][:-2])\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = torch.nn.Linear(2048, self.num_class)\n",
    "        # self.model.layer4[2] = resnetModel.CustBottleneck(2048,512,self.activations_hook)\n",
    "        # self.model.fc = torch.nn.Linear(2048,3)\n",
    "        \n",
    "    def forward(self,inTensor:torch.tensor):\n",
    "        x = self.features_conv(inTensor)\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\assaw/.cache\\torch\\hub\\pytorch_vision_v0.19.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResnetModel(\n",
       "  (features_conv): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', pretrained=True)\n",
    "resnet50 = ResnetModel(model)\n",
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGGModel(torchvision.models.vgg19(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResnetModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type              | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | features_conv | Sequential        | 23.5 M | train\n",
      "1 | avgpool       | AdaptiveAvgPool2d | 0      | train\n",
      "2 | fc            | Linear            | 6.1 K  | train\n",
      "------------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.057    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb1070d03994436b743ed8b86056721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2d770edd2c42869a446464608bec3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0742e573c40466e816842dfce191e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d124925ed8a4968b09d8310937d0b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1ba939597b45d8a6d4c3dda6ff2501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8237b6c67745e5a644ce99dbe1fd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a36179086e42c09a24282d3b8179c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61043c25eee64d328fd82e0e35971f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed065caffc3444fa41e1f1b7b93c70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501e8cd3667a479a93ac7e9c79c33dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d235fef34c47dab287a1ea04d69ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec51f6538f574509adedb3182a8715f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "for x in ExperimentModel.existingModels:\n",
    "    print(x.__class__.__name__)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # early_stopping = EarlyStopping(\n",
    "    #     monitor='val_loss',  # Metric to monitor\n",
    "    #     patience=5000,          # Number of epochs with no improvement after which training will be stopped\n",
    "    #     verbose=False,        # Verbosity mode\n",
    "    #     mode='min'           # Mode can be 'min', 'max', or 'auto'\n",
    "    # )\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=f\"{x.__class__.__name__}\")\n",
    "    \n",
    "\n",
    "    trainer = L.Trainer(max_epochs = 10,accelerator='gpu', devices='auto', precision='16-mixed',logger=logger)\n",
    "    trainer.fit(model=x,train_dataloaders=trainLoader,val_dataloaders=valLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\assaw/.cache\\torch\\hub\\pytorch_vision_v0.19.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "not cached:torch.Size([1, 2048, 8, 8])\n",
      "pooled shape: torch.Size([2048])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', pretrained=True)\n",
    "resnetPath = r'C:\\Users\\assaw\\Documents\\c_stuff\\Python\\machine learning\\ISAIConference\\tb_logs\\ResnetModel\\version_20\\checkpoints'\n",
    "resnet50 = ResnetModel.load_from_checkpoint('\\\\'.join([resnetPath,os.listdir(resnetPath)[-1]]),resnet = model)\n",
    "torch.cuda.empty_cache()\n",
    "out,label = resnet50.visualize(valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.9179e-03,  0.0000e+00,  2.6086e-03,  ...,  1.9394e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-4.6089e-03,  0.0000e+00, -7.6998e-03,  ..., -6.2716e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 4.1731e-04,  0.0000e+00, -1.8500e-03,  ..., -5.6967e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -5.4876e-02]],\n",
      "\n",
      "         [[-3.1212e-03,  0.0000e+00,  0.0000e+00,  ...,  1.3000e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.8807e-03,  0.0000e+00, -5.8599e-03,  ...,  3.1716e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.0221e-03,  0.0000e+00, -8.0505e-03,  ...,  3.0165e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-7.1189e-04,  0.0000e+00,  1.5358e-03,  ..., -1.6744e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-4.5500e-03,  0.0000e+00, -2.5953e-03,  ..., -1.7525e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0241e-03,  0.0000e+00,  1.0099e-03,  ...,  1.3308e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6921e-01, -5.0318e-01, -1.5486e-01,  ...,  7.5217e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-7.8460e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.6115e-03,  0.0000e+00,  3.9084e-03,  ..., -9.7352e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 9.7420e-04,  0.0000e+00,  1.2652e-04,  ...,  3.9102e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.5712e-03,  0.0000e+00, -1.4440e-03,  ..., -1.6586e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.3733e-03,  0.0000e+00,  5.3919e-03,  ...,  4.3609e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-5.0619e-04,  0.0000e+00,  6.6820e-04,  ...,  3.9884e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.7248e-03,  0.0000e+00, -7.6322e-03,  ..., -2.1216e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-8.7203e-03,  0.0000e+00, -3.5621e-03,  ..., -4.4202e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.6255e-02,  0.0000e+00,  4.6206e-03,  ...,  9.5355e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[-3.0395e-04,  0.0000e+00,  6.7360e-04,  ...,  2.2342e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.5371e-03,  0.0000e+00,  2.4671e-03,  ...,  5.3024e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-6.5011e-04,  0.0000e+00, -3.4626e-03,  ...,  1.1318e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.7813e-04,  0.0000e+00, -1.5952e-03,  ...,  9.4413e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.7716e-03,  0.0000e+00, -1.2350e-03,  ..., -4.8733e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.8711e-03,  0.0000e+00, -4.3360e-03,  ..., -4.0853e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4800e-03,  0.0000e+00, -7.4628e-04,  ..., -4.9426e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.2317e-04,  0.0000e+00, -8.8054e-04,  ..., -3.4739e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.7725e-03,  0.0000e+00, -1.0545e-03,  ..., -2.2875e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5246e-01, -1.4367e-01, -9.1519e-04,  ..., -1.8119e-03,\n",
      "            0.0000e+00, -9.5401e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -2.4240e-02],\n",
      "          [-6.4511e-05,  0.0000e+00, -2.3400e-03,  ..., -2.4523e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.5882e-03,  0.0000e+00, -2.9997e-03,  ..., -4.4585e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-9.5377e-04,  0.0000e+00, -3.0205e-03,  ..., -8.2911e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-9.7637e-04,  0.0000e+00, -4.4788e-03,  ..., -2.7856e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.4180e-04,  0.0000e+00, -9.6655e-04,  ..., -1.9839e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.9630e-03,  0.0000e+00, -3.8807e-04,  ..., -5.8433e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.4473e-03,  0.0000e+00, -3.1107e-03,  ..., -4.1204e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.3974e-03,  0.0000e+00, -3.1309e-03,  ..., -4.7765e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 1.2109e-04,  0.0000e+00, -3.4593e-03,  ...,  7.5996e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.6550e-03,  0.0000e+00, -1.6518e-01,  ...,  4.5209e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-9.7986e-04,  0.0000e+00, -1.6896e-03,  ..., -1.7150e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.7754e-03,  0.0000e+00, -8.6303e-01,  ...,  1.0377e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.5408e-04,  0.0000e+00, -1.8972e-01,  ..., -3.2512e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.1220e-03,  0.0000e+00, -2.4970e-03,  ..., -3.7897e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.8456e-04,  0.0000e+00,  1.3918e-03,  ..., -3.1637e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.7335e-03,  0.0000e+00,  1.8701e-03,  ..., -1.3286e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 4.0287e-03,  0.0000e+00,  1.3531e-03,  ..., -1.8887e-05,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2090e-01, -8.6030e-02, -1.8256e-03,  ..., -6.7500e-04,\n",
      "            0.0000e+00, -8.5776e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.3248e-04,  0.0000e+00, -9.9537e-04,  ..., -7.6146e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.5934e-03,  0.0000e+00, -4.0151e-03,  ..., -5.2753e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.8776e-03,  0.0000e+00, -1.1322e-03,  ...,  1.1770e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 7.9604e-04,  0.0000e+00, -5.1017e-03,  ..., -8.9360e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-9.6479e-04,  0.0000e+00, -1.0889e-03,  ..., -2.6493e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 4.5410e-03,  0.0000e+00,  1.9330e-03,  ...,  2.3879e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.8549e-03,  0.0000e+00,  7.2218e-04,  ...,  2.4428e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-9.5456e-04,  0.0000e+00, -2.2187e-03,  ..., -3.1531e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[-5.7604e-05,  0.0000e+00,  9.3353e-04,  ...,  1.1701e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.0130e-03,  0.0000e+00,  3.4685e-03,  ...,  4.8411e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.4623e-04,  0.0000e+00, -2.1295e-03,  ..., -2.0534e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.3118e-03,  0.0000e+00, -2.0544e-04,  ...,  1.0145e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.1565e-03,  0.0000e+00, -3.2352e-04,  ..., -5.3250e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.0717e-03,  0.0000e+00, -5.6901e-03,  ..., -4.2809e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4196e-03,  0.0000e+00, -6.6155e-04,  ..., -3.3468e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.2920e-03,  0.0000e+00, -7.0643e-04,  ..., -2.8669e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.1406e-03,  0.0000e+00, -8.9308e-05,  ..., -8.0522e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1521e-01, -4.7499e-01, -5.5684e-01,  ..., -2.5344e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.4752e-02,  0.0000e+00, -4.6325e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.2160e-03,  0.0000e+00, -2.2842e-03,  ..., -7.3685e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.0143e-03,  0.0000e+00, -3.6833e-03,  ..., -6.6406e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-4.5534e-04,  0.0000e+00, -2.9429e-03,  ..., -1.5366e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.4716e-03,  0.0000e+00, -5.0266e-03,  ..., -4.2673e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.1947e-03,  0.0000e+00, -2.8384e-03,  ..., -4.9541e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 4.8985e-03,  0.0000e+00,  2.3688e-03,  ...,  2.0603e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.3859e-03,  0.0000e+00,  1.4296e-03,  ...,  2.3795e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.1402e-04,  0.0000e+00, -9.1489e-04,  ..., -9.8973e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 1.0839e-03,  0.0000e+00,  2.3837e-03,  ...,  2.5231e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.8655e-03,  0.0000e+00,  5.7364e-03,  ...,  6.7388e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.4746e-04,  0.0000e+00, -1.0343e-03,  ...,  4.0891e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.9037e-03,  0.0000e+00, -4.1608e-01,  ...,  4.3689e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.7998e-03,  0.0000e+00, -9.9044e-04,  ..., -5.0977e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.7517e-03,  0.0000e+00, -3.7165e-03,  ..., -3.8406e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-2.0247e-03,  0.0000e+00, -2.4190e-03,  ..., -4.5352e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 6.8837e-04,  0.0000e+00, -1.0724e-04,  ..., -2.5473e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.8790e-03,  0.0000e+00,  1.3961e-03,  ..., -9.2918e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1592e-01, -7.8343e-01, -2.8666e-01,  ..., -3.4660e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.5074e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.7201e-03,  0.0000e+00, -4.1240e-03,  ..., -4.6998e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.9631e-03,  0.0000e+00, -6.1545e-03,  ..., -5.9247e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4153e-03,  0.0000e+00, -3.1751e-03,  ..., -5.5125e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.9738e-03,  0.0000e+00, -4.7842e-03,  ..., -3.1709e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.3093e-03,  0.0000e+00, -2.1141e-03,  ..., -3.6857e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.8136e-03,  0.0000e+00,  1.4819e-03,  ...,  1.1400e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.3600e-04,  0.0000e+00, -1.1009e-03,  ...,  1.5971e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 7.8786e-04,  0.0000e+00, -1.4265e-03,  ..., -1.6450e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 7.1369e-03,  0.0000e+00,  1.5153e-03,  ...,  3.6080e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.5310e-03,  0.0000e+00, -7.3962e-03,  ..., -3.6529e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 7.3056e-05,  0.0000e+00, -2.4439e-03,  ..., -9.4748e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -8.8066e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -1.3514e-01]],\n",
      "\n",
      "         [[-5.2964e-03,  0.0000e+00,  0.0000e+00,  ..., -8.5633e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0429e-02,  0.0000e+00, -1.2494e-02,  ..., -1.2550e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-5.1236e-03,  0.0000e+00, -1.1168e-02,  ...,  4.0031e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4649e-03,  0.0000e+00,  1.2302e-04,  ..., -2.5432e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-6.1690e-03,  0.0000e+00, -4.0586e-03,  ..., -3.5347e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.8983e-05,  0.0000e+00,  3.7402e-03,  ...,  2.1746e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5918e-01, -3.4753e-01, -2.3628e-01,  ...,  7.1697e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0272e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.1966e-03,  0.0000e+00,  4.3206e-03,  ..., -3.7444e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.4683e-03,  0.0000e+00,  4.5055e-04,  ...,  4.2471e-03,\n",
      "            0.0000e+00, -4.5068e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.2060e-04,  0.0000e+00, -2.8189e-03,  ..., -2.4566e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.7489e-03,  0.0000e+00,  4.2163e-03,  ...,  7.0045e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.9251e-04,  0.0000e+00,  2.8332e-03,  ...,  6.3515e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-7.4923e-03,  0.0000e+00, -8.0478e-03,  ..., -2.1108e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-9.8967e-03,  0.0000e+00, -4.3103e-03,  ..., -3.0893e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.3716e-02,  0.0000e+00,  2.2972e-03,  ...,  1.0800e-02,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 2.2443e-03,  0.0000e+00,  1.8571e-03,  ...,  3.0093e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.1775e-03,  0.0000e+00,  3.5646e-03,  ...,  4.8459e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.1515e-03,  0.0000e+00, -1.6754e-03,  ...,  8.2979e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.4936e-03,  0.0000e+00, -8.8528e-01,  ...,  1.2246e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.1496e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.5940e-04,  0.0000e+00, -3.4591e-01,  ..., -2.3343e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.3544e-03,  0.0000e+00, -3.4147e-03,  ..., -1.8680e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-2.9972e-04,  0.0000e+00, -4.4401e-07,  ..., -2.1248e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.3774e-03,  0.0000e+00,  1.1189e-03,  ..., -1.4721e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3952e-03,  0.0000e+00,  1.0441e-03,  ..., -1.5370e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3132e-01, -1.4103e-01, -2.0160e-03,  ..., -1.9865e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-9.8644e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.8750e-03,  0.0000e+00, -4.6814e-03,  ..., -5.3190e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.7635e-03,  0.0000e+00, -5.3732e-03,  ..., -5.5118e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.0432e-03,  0.0000e+00, -3.5577e-03,  ..., -1.4945e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.3212e-04,  0.0000e+00, -3.5798e-03,  ..., -2.9566e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.3169e-03,  0.0000e+00, -1.7292e-03,  ..., -3.3419e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.7831e-03,  0.0000e+00, -6.3047e-04,  ...,  1.5611e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.5173e-04,  0.0000e+00, -8.7654e-04,  ...,  1.2300e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.1148e-03,  0.0000e+00, -5.6463e-04,  ..., -5.3379e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 1.6212e-03,  0.0000e+00,  2.1912e-03,  ...,  2.1526e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3466e-03,  0.0000e+00, -1.3322e-01,  ...,  6.0670e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.1701e-04,  0.0000e+00, -1.6056e-03,  ...,  3.2290e-05,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -1.3716e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -3.9846e-01, -2.0470e+00,  ...,  7.3595e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00, -1.7052e-02, -1.3032e+00,  ..., -3.1162e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.8135e-03,  0.0000e+00,  0.0000e+00,  ..., -3.9662e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -7.6012e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-8.4971e-04,  0.0000e+00, -4.2290e-04,  ..., -3.0771e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.9555e-04,  0.0000e+00,  3.5108e-04,  ..., -2.2172e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.3628e-03,  0.0000e+00,  9.4025e-04,  ..., -1.6406e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3605e-02,  0.0000e+00, -1.4168e-03,  ..., -3.4875e-01,\n",
      "           -1.5919e-01, -6.9217e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.6905e-03,  0.0000e+00, -2.2655e-03,  ..., -2.2410e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.5351e-03,  0.0000e+00, -4.8565e-03,  ..., -5.2213e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-3.6081e-04,  0.0000e+00, -1.7194e-03,  ...,  7.4922e-06,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.3357e-03,  0.0000e+00, -5.6752e-03,  ..., -1.6237e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.3466e-03,  0.0000e+00, -2.7862e-03,  ..., -3.7863e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.3168e-03,  0.0000e+00,  0.0000e+00,  ...,  1.5385e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 6.9448e-04,  0.0000e+00, -6.9707e-05,  ...,  2.6909e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.2966e-03,  0.0000e+00, -1.3927e-03,  ..., -4.2290e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[-4.4606e-04,  0.0000e+00,  9.0027e-04,  ...,  5.9037e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.4496e-03,  0.0000e+00,  2.7619e-03,  ...,  4.7105e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.1164e-03,  0.0000e+00, -1.4167e-03,  ...,  1.3761e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.3610e-03,  0.0000e+00,  0.0000e+00,  ...,  1.7192e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-8.8192e-04,  0.0000e+00,  1.0316e-03,  ..., -2.0175e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.9890e-03,  0.0000e+00, -3.2698e-03,  ..., -3.2685e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.1840e-03,  0.0000e+00, -1.8775e-03,  ..., -4.1463e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 9.5434e-04,  0.0000e+00, -6.6209e-04,  ..., -3.0273e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.2881e-03,  0.0000e+00,  1.6896e-03,  ..., -1.3353e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8545e-01, -3.6926e-02, -1.8839e-03,  ..., -2.8839e-03,\n",
      "            0.0000e+00, -1.0307e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.6936e-03,  0.0000e+00, -2.0484e-03,  ..., -3.9524e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.2644e-03,  0.0000e+00, -5.2644e-03,  ..., -5.9614e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.7532e-04,  0.0000e+00, -1.7844e-03,  ..., -4.1710e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-8.9707e-04,  0.0000e+00, -4.6141e-03,  ..., -1.2186e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.3841e-04,  0.0000e+00,  0.0000e+00,  ..., -2.4408e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.9033e-03,  0.0000e+00,  0.0000e+00,  ...,  1.4605e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 7.5353e-04,  0.0000e+00, -1.0146e-03,  ...,  2.0698e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.3554e-04,  0.0000e+00,  0.0000e+00,  ..., -3.0288e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[-4.2957e-04,  0.0000e+00,  1.0101e-03,  ...,  4.2703e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.5881e-03,  0.0000e+00,  3.8287e-03,  ...,  4.7866e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-6.4823e-04,  0.0000e+00, -1.3754e-03,  ...,  3.2369e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -6.1977e-02]],\n",
      "\n",
      "         [[ 4.1504e-03,  0.0000e+00,  2.6907e-03,  ...,  2.5315e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-6.8902e-04,  0.0000e+00,  2.0490e-03,  ..., -1.7240e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.6509e-03,  0.0000e+00, -4.1419e-03,  ..., -2.7766e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-8.8986e-04,  0.0000e+00, -7.1066e-04,  ..., -4.6350e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 9.1468e-04,  0.0000e+00, -1.2773e-03,  ..., -3.2393e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.6223e-03,  0.0000e+00,  1.0863e-03,  ..., -6.0136e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1779e-01, -8.7151e-01, -1.1879e+00,  ..., -1.9695e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.4809e-01, -4.5492e-01, -6.5074e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.8999e-03,  0.0000e+00, -1.5595e-03,  ..., -3.1944e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.1106e-03,  0.0000e+00, -4.5195e-03,  ..., -4.2494e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-2.0092e-04,  0.0000e+00, -1.8296e-03,  ..., -4.3288e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.2550e-04,  0.0000e+00, -4.1240e-03,  ..., -7.6013e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.1167e-03,  0.0000e+00, -2.4816e-03,  ..., -2.7928e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.5948e-03,  0.0000e+00,  6.1756e-04,  ...,  2.0750e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-6.1546e-04,  0.0000e+00, -2.1779e-03,  ...,  1.7339e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-7.5728e-04,  0.0000e+00, -2.5881e-03,  ..., -2.2569e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 7.2291e-03,  0.0000e+00,  2.0950e-03,  ...,  1.5907e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.7444e-03,  0.0000e+00, -7.2791e-03,  ..., -5.5933e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.5642e-04,  0.0000e+00, -2.9720e-03,  ..., -3.3737e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-2.1840e-03,  0.0000e+00, -4.7415e-03,  ...,  2.3056e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.0751e-03,  0.0000e+00, -5.5932e-03,  ...,  7.1547e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.7971e-04,  0.0000e+00, -5.1405e-03,  ...,  5.3945e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.3920e-03,  0.0000e+00,  8.1955e-04,  ..., -2.2533e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-5.8343e-03,  0.0000e+00, -2.9953e-03,  ..., -3.2956e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.6254e-04,  0.0000e+00,  3.8050e-03,  ...,  5.2392e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3732e-01, -2.4333e-01, -2.0589e-01,  ...,  6.9411e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.4047e-03,  0.0000e+00,  2.9744e-03,  ..., -3.5274e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-5.9444e-04,  0.0000e+00, -2.3283e-04,  ...,  3.1190e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 4.2232e-03,  0.0000e+00,  2.3580e-04,  ...,  4.3203e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.0755e-03,  0.0000e+00,  5.6607e-03,  ...,  8.1572e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.0769e-04,  0.0000e+00,  4.1957e-03,  ...,  5.7034e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-7.7816e-03,  0.0000e+00, -7.1695e-03,  ..., -1.3464e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-8.9810e-03,  0.0000e+00, -4.9708e-03,  ..., -4.7521e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.3802e-02,  0.0000e+00,  1.5062e-03,  ...,  9.3515e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 7.0326e-04,  0.0000e+00,  2.0626e-03,  ...,  2.2807e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.9513e-03,  0.0000e+00,  4.2689e-03,  ...,  6.0539e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-9.6434e-04,  0.0000e+00, -5.9659e-04,  ...,  7.4232e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00, -5.0767e-02]],\n",
      "\n",
      "         [[ 2.9846e-03,  0.0000e+00, -8.7214e-01,  ...,  1.0205e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.4793e-04,  0.0000e+00,  1.7836e-03,  ..., -3.0451e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.0351e-03,  0.0000e+00, -3.4917e-03,  ..., -2.5191e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-8.4084e-04,  0.0000e+00, -9.8702e-05,  ..., -3.5746e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.1859e-03,  0.0000e+00,  1.3190e-03,  ..., -1.8723e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.9341e-03,  0.0000e+00,  1.0267e-03,  ..., -1.4036e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6908e-01, -6.6836e-01, -1.9854e-03,  ..., -1.7318e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-6.7987e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.0681e-01,  0.0000e+00, -4.2268e-03,  ..., -4.4832e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.5948e-03,  0.0000e+00, -5.1389e-03,  ..., -4.4051e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-7.0822e-04,  0.0000e+00, -2.9449e-03,  ..., -1.0882e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.9435e-04,  0.0000e+00, -4.6055e-03,  ..., -2.2309e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.3982e-03,  0.0000e+00, -2.4116e-03,  ..., -3.7495e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.9569e-03,  0.0000e+00,  7.4072e-04,  ...,  1.0926e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.4104e-04,  0.0000e+00, -1.2689e-03,  ...,  1.7204e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.5851e-03,  0.0000e+00, -1.2143e-03,  ..., -2.5878e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 1.2562e-03,  0.0000e+00,  0.0000e+00,  ...,  2.2786e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.8182e-03,  0.0000e+00,  0.0000e+00,  ...,  4.3250e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.1366e-03,  0.0000e+00, -2.1867e-03,  ...,  2.2166e-05,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.2342e-03,  0.0000e+00, -4.3108e-01,  ...,  1.9631e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -8.3103e-03,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 8.1180e-04,  0.0000e+00, -3.0977e-01,  ..., -1.2055e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-5.9066e-04,  0.0000e+00, -1.4148e-03,  ..., -5.2187e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4543e-03,  0.0000e+00, -2.1529e-03,  ..., -3.5205e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.8709e-04,  0.0000e+00, -7.6527e-04,  ..., -2.2989e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 9.0109e-04,  0.0000e+00, -1.7827e-03,  ..., -1.9049e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4734e-01, -5.2130e-02,  2.2326e-04,  ..., -2.0379e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-6.1460e-04,  0.0000e+00, -1.7426e-03,  ..., -3.1929e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.8496e-03,  0.0000e+00, -3.8833e-03,  ..., -5.2355e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.6316e-04,  0.0000e+00, -9.3554e-04,  ..., -2.8344e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.9069e-04,  0.0000e+00, -3.1068e-03,  ..., -9.9090e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.1603e-03,  0.0000e+00, -2.0793e-03,  ..., -3.1668e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.6230e-03,  0.0000e+00, -1.3774e-04,  ...,  1.5562e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-2.3485e-04,  0.0000e+00, -1.2029e-03,  ...,  1.5805e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.8351e-03,  0.0000e+00, -4.0415e-04,  ..., -3.7940e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 1.3606e-03,  0.0000e+00,  1.0348e-03,  ...,  1.3036e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.2737e-03,  0.0000e+00, -1.6244e-05,  ...,  3.2330e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.3373e-04,  0.0000e+00, -3.2771e-04,  ...,  5.9515e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 6.0972e-03,  0.0000e+00,  3.8482e-03,  ..., -3.4472e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.8331e-03,  0.0000e+00,  5.3505e-03,  ...,  1.6892e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.3967e-03,  0.0000e+00, -1.1789e-03,  ...,  3.6224e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.1920e-04,  0.0000e+00, -8.0989e-04,  ..., -3.6721e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3227e-04,  0.0000e+00, -1.0644e-03,  ..., -3.5697e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.1949e-03,  0.0000e+00,  1.0859e-03,  ..., -1.6678e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.9595e-01, -7.0430e-01, -8.8968e-01,  ...,  2.1189e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0024e-01, -8.1024e-02, -3.5263e-01,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.7139e-03,  0.0000e+00, -1.1496e-03,  ..., -2.7360e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.6489e-03,  0.0000e+00, -6.1934e-03,  ..., -4.9483e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.0722e-05,  0.0000e+00, -3.5170e-03,  ..., -7.6971e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.8503e-04,  0.0000e+00, -4.9682e-03,  ...,  1.9295e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.2865e-03,  0.0000e+00, -1.4823e-03,  ..., -2.8256e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.6466e-03,  0.0000e+00, -5.9739e-05,  ...,  1.0774e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.2156e-03,  0.0000e+00, -1.3669e-03,  ...,  1.7036e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.6126e-03,  0.0000e+00, -5.6833e-04,  ...,  7.5073e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 8.4129e-03,  0.0000e+00,  4.2618e-03,  ...,  4.5424e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 1.7775e-03,  0.0000e+00, -3.6601e-03,  ..., -3.2345e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.3832e-03,  0.0000e+00, -1.2245e-03,  ..., -4.6077e-06,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.7869e-03,  0.0000e+00,  0.0000e+00,  ..., -1.1897e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-6.6108e-03,  0.0000e+00,  0.0000e+00,  ...,  2.3076e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.4651e-03,  0.0000e+00, -8.1899e-03,  ...,  1.8125e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.8441e-03,  0.0000e+00,  2.2304e-04,  ..., -8.7852e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-5.2575e-03,  0.0000e+00, -3.9246e-03,  ..., -3.9481e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.1178e-04,  0.0000e+00,  3.6743e-03,  ...,  2.4119e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9263e-01, -1.7433e-01,  9.7700e-03,  ...,  4.9506e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 2.3724e-04,  0.0000e+00,  2.0372e-04,  ..., -6.5442e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.1263e-04,  0.0000e+00, -1.5850e-03,  ..., -1.0288e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.8773e-03,  0.0000e+00, -1.1107e-03,  ..., -2.9849e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.7158e-03,  0.0000e+00,  4.6668e-03,  ...,  6.0460e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0367e-03,  0.0000e+00,  1.5684e-03,  ...,  3.8341e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-7.7788e-03,  0.0000e+00, -8.1466e-03,  ..., -3.6212e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.1880e-02,  0.0000e+00, -6.0085e-03,  ..., -5.2284e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.1997e-02,  0.0000e+00, -1.2263e-03,  ...,  8.1236e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[ 1.5068e-03,  0.0000e+00,  1.7403e-03,  ...,  3.0368e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 4.3870e-03,  0.0000e+00,  2.8143e-03,  ...,  5.7721e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-7.3382e-04,  0.0000e+00, -2.4307e-03,  ...,  1.3255e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.0478e-03,  0.0000e+00,  0.0000e+00,  ..., -2.0167e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.5067e-03,  0.0000e+00,  0.0000e+00,  ..., -2.9734e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.0449e-03,  0.0000e+00,  0.0000e+00,  ..., -1.8329e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.8289e-03,  0.0000e+00, -6.0117e-04,  ..., -3.3807e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 5.1294e-04,  0.0000e+00, -9.1288e-04,  ..., -3.2114e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.4907e-04,  0.0000e+00, -1.6903e-03,  ..., -4.2678e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5328e-01,  0.0000e+00, -7.7795e-04,  ..., -1.2374e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-3.8179e-03,  0.0000e+00, -3.5412e-03,  ..., -4.7057e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.5444e-03,  0.0000e+00, -5.9132e-03,  ..., -6.6351e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-3.4172e-04,  0.0000e+00, -3.9180e-03,  ..., -7.5166e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 3.4390e-04,  0.0000e+00, -3.8392e-03,  ..., -2.0848e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.6262e-03,  0.0000e+00, -1.5628e-03,  ..., -4.0941e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.9761e-04,  0.0000e+00, -7.6691e-04,  ...,  9.6555e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.5290e-03,  0.0000e+00, -1.3385e-03,  ...,  1.1031e-03,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.0447e-03,  0.0000e+00,  0.0000e+00,  ...,  6.7042e-04,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "cached:torch.Size([1, 512, 15, 15])\n",
      "torch.Size([512])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([15, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2eaf4d7e7d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = VGGModel.load_from_checkpoint(r'tb_logs\\VGGModel\\version_26\\checkpoints\\epoch=19-step=720.ckpt',vgg = torchvision.models.vgg19(pretrained=False))\n",
    "outvgg,path = model.visualize(valLoader)\n",
    "\n",
    "plt.imshow(outvgg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1][0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentModel.existingModels[0].valPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,_,_ = next(iter(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze(img[0],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.eval()\n",
    "img,lab,path = next(iter(trainLoader))\n",
    "pred = resnet50(torch.unsqueeze(img[0],0))\n",
    "print(pred)\n",
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 1].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = resnet50.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = resnet50.get_activations(torch.unsqueeze(img[0],0)).detach()\n",
    "print(activations.shape)\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(out[1][0])\n",
    "heatmap = cv2.resize(out[0][0].numpy(), (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./test.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"img.jpg\",superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.19.0', \"vgg19\",{\"num_classes\":3}, pretrained=True, )\n",
    "model.classifier[6] = torch.nn.Linear(4096,3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input dimension should be at least 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(predicted_labels \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[52], line 129\u001b[0m, in \u001b[0;36mResnetModel.forward\u001b[1;34m(self, inTensor)\u001b[0m\n\u001b[0;32m    127\u001b[0m     hook \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mregister_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations_hook)\n\u001b[0;32m    128\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 129\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:1267\u001b[0m, in \u001b[0;36mAdaptiveAvgPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptive_avg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\functional.py:1259\u001b[0m, in \u001b[0;36madaptive_avg_pool2d\u001b[1;34m(input, output_size)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(adaptive_avg_pool2d, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, output_size)\n\u001b[1;32m-> 1259\u001b[0m _output_size \u001b[38;5;241m=\u001b[39m \u001b[43m_list_with_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(\u001b[38;5;28minput\u001b[39m, _output_size)\n",
      "File \u001b[1;32mc:\\Users\\assaw\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\utils.py:39\u001b[0m, in \u001b[0;36m_list_with_default\u001b[1;34m(out_size, defaults)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out_size\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(defaults) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_size):\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput dimension should be at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(out_size)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     43\u001b[0m     v \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m d \u001b[38;5;28;01mfor\u001b[39;00m v, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(out_size, defaults[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(out_size) :])\n\u001b[0;32m     44\u001b[0m ]\n",
      "\u001b[1;31mValueError\u001b[0m: Input dimension should be at least 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.cuda.empty_cache()\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.204, 0.052, 0.175],device='cuda'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "accHistory = []\n",
    "lossHistory = []\n",
    "valAccHistory = []\n",
    "valLabs = []\n",
    "valPreds = []\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = []\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for inputs, labels, _ in trainLoader:\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "        running_accuracy.append(accuracy)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1} - Loss: {running_loss / len(trainLoader)}\")\n",
    "    print(F\"Accuracy: {sum(running_accuracy)/len(running_accuracy)}\")\n",
    "    accHistory.append(sum(running_accuracy)/len(running_accuracy))\n",
    "    lossHistory.append(running_loss / len(trainLoader))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        runningValAccHistory = []\n",
    "        runningValLabs = []\n",
    "        runningValPreds = []\n",
    "        for inputs, labels, _ in valLoader:\n",
    "\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the predicted labels\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)\n",
    "\n",
    "            runningValAccHistory.append(accuracy)\n",
    "            runningValLabs.append(labels)\n",
    "            runningValPreds.append(predicted_labels)\n",
    "\n",
    "        # print(f\"Validation Loss: {loss.item()}\")\n",
    "        valPreds.append(runningValPreds)\n",
    "        valLabs.append(runningValLabs)\n",
    "        print(f\"Validation Accuracy: {sum(runningValAccHistory)/len(valLoader)}\")\n",
    "        valAccHistory.append(sum(runningValAccHistory)/len(valLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "idx = 25\n",
    "predsTest = torch.cat(valPreds[idx-1])\n",
    "labelsTest = torch.cat(valLabs[idx-1])\n",
    "print(valAccHistory[idx-1])\n",
    "print(classification_report(predsTest.cpu(),labelsTest.cpu()))\n",
    "cm= confusion_matrix(predsTest.cpu(),labelsTest.cpu(),normalize='true')\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f',)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valAccHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input , label, _ = next(iter(valLoader))\n",
    "# Move the inputs and labels to the device\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "predicted_labels = torch.argmax(outputs, dim=1)\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with the data\n",
    "df = pd.DataFrame({'Epoch': range(len(accHistory)), 'Accuracy': accHistory, 'Loss': lossHistory, 'Validation Accuracy': valAccHistory})\n",
    "\n",
    "# Create the line plot\n",
    "sns.relplot(data=df, x='Epoch', y='Accuracy', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Loss', kind='line')\n",
    "sns.relplot(data=df, x='Epoch', y='Validation Accuracy', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnetClassic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "label = []\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, _ in valLoader:\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label = labels\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute the predicted labels\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        accuracy = torch.sum(predicted_labels == labels).item() / labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.argmax(1))\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
